<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" class="chrometwo"><head><title>Audit logs in Red Hat Developer Hub</title><link rel="stylesheet" type="text/css" href="Common_Content/css/default.css"/><meta name="generator" content="publican v4.3.2"/><meta name="description" content="As a Red Hat Developer Hub (RHDH) administrator, you can track user activities, system events, and data changes with Developer Hub audit logs."/><link rel="next" href="#assembly-audit-log" title="1. Audit logs in Red Hat Developer Hub"/><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><script type="text/javascript" src="Common_Content/scripts/jquery-1.7.1.min.js"> </script><script type="text/javascript" src="Common_Content/scripts/utils.js"> </script><script type="text/javascript" src="Common_Content/scripts/highlight.js/highlight.pack.js"> </script></head><body><div id="chrometwo"><div id="main"><section xml:lang="en-US" class="article" id="idm46366085194064"><div class="titlepage"><div><div class="producttitle"><span class="productname">Red Hat Developer Hub</span> <span class="productnumber">1.7</span></div><div><h1 class="title">Audit logs in Red Hat Developer Hub</h1></div><div><h3 class="subtitle"><em>Tracking user activities, system events, and data changes with Red Hat Developer Hub audit logs</em></h3></div><div><div xml:lang="en-US" class="authorgroup"><span class="orgname">Red Hat Customer Content Services</span></div></div><div><a href="#idm46366066143408">Legal Notice</a></div><div><div class="abstract"><p class="title"><strong>Abstract</strong></p><div class="para">
				As a Red Hat Developer Hub (RHDH) administrator, you can track user activities, system events, and data changes with Developer Hub audit logs.
			</div></div></div></div><hr/></div><div class="toc"><ul class="toc"><li><span class="section"><a href="#assembly-audit-log">1. Audit logs in Red Hat Developer Hub</a></span></li><li><span class="section"><a href="#con-audit-log-config_assembly-audit-log">2. Configuring audit logs for Developer Hub on OpenShift Container Platform</a></span><ul><li><span class="section"><a href="#proc-forward-audit-log-splunk_assembly-audit-log">2.1. Forwarding Red Hat Developer Hub audit logs to Splunk</a></span></li></ul></li><li><span class="section"><a href="#proc-audit-log-view_assembly-audit-log">3. Viewing audit logs in Developer Hub</a></span></li></ul></div><section class="section" id="assembly-audit-log"><div class="titlepage"><div><div><h2 class="title">1. Audit logs in Red Hat Developer Hub</h2></div></div></div><p>
			Audit logs are a chronological set of records documenting the user activities, system events, and data changes that affect your Red Hat Developer Hub users, administrators, or components. Administrators can view Developer Hub audit logs in the OpenShift Container Platform web console to monitor scaffolder events, changes to the RBAC system, and changes to the Catalog database. Audit logs include the following information:
		</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
					Name of the audited event
				</li><li class="listitem">
					Actor that triggered the audited event, for example, terminal, port, IP address, or hostname
				</li><li class="listitem">
					Event metadata, for example, date, time
				</li><li class="listitem">
					Event status, for example, <code class="literal">success</code>, <code class="literal">failure</code>
				</li><li class="listitem">
					Severity levels, for example, <code class="literal">info</code>, <code class="literal">debug</code>, <code class="literal">warn</code>, <code class="literal">error</code>
				</li></ul></div><p>
			You can use the information in the audit log to achieve the following goals:
		</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Enhance security</span></dt><dd>
						Trace activities, including those initiated by automated systems and software templates, back to their source. Know when software templates are executed, as well as the details of application and component installations, updates, configuration changes, and removals.
					</dd><dt><span class="term">Automate compliance</span></dt><dd>
						Use streamlined processes to view log data for specified points in time for auditing purposes or continuous compliance maintenance.
					</dd><dt><span class="term">Debug issues</span></dt><dd>
						Use access records and activity details to fix issues with software templates or plugins.
					</dd></dl></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
				Audit logs are not forwarded to the internal log store by default because this does not provide secure storage. You are responsible for ensuring that the system to which you forward audit logs is compliant with your organizational and governmental regulations, and is properly secured.
			</p></div></div><div class="itemizedlist _additional-resources"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist _additional-resources" type="disc"><li class="listitem">
					For more information about logging in OpenShift Container Platform, see <a class="link" href="https://docs.openshift.com/container-platform/latest/observability/logging/cluster-logging.html">About Logging</a>
				</li></ul></div></section><section class="section" id="con-audit-log-config_assembly-audit-log"><div class="titlepage"><div><div><h2 class="title">2. Configuring audit logs for Developer Hub on OpenShift Container Platform</h2></div></div></div><p>
			Use the OpenShift Container Platform web console to configure the following OpenShift Container Platform logging components to use audit logging for Developer Hub:
		</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Logging deployment</span></dt><dd>
						Configure the logging environment, including both the CPU and memory limits for each logging component. For more information, see <a class="link" href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.16/html-single/logging/index#cluster-logging-memory">Red Hat OpenShift Container Platform - Configuring your Logging deployment</a>.
					</dd><dt><span class="term">Logging collector</span></dt><dd>
						Configure the <code class="literal">spec.collection</code> stanza in the <code class="literal">ClusterLogging</code> custom resource (CR) to use a supported modification to the log collector and collect logs from <code class="literal">STDOUT</code>. For more information, see <a class="link" href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.16/html-single/logging/index#cluster-logging-collector">Red Hat OpenShift Container Platform - Configuring the logging collector</a>.
					</dd><dt><span class="term">Log forwarding</span></dt><dd>
						Send logs to specific endpoints inside and outside your OpenShift Container Platform cluster by specifying a combination of outputs and pipelines in a <code class="literal">ClusterLogForwarder</code> CR. For more information, see <a class="link" href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.16/html-single/logging/index#cluster-logging-json-log-forwarding_cluster-logging-enabling-json-logging">Red Hat OpenShift Container Platform - Enabling JSON log forwarding</a> and <a class="link" href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.16/html-single/logging/index#configuring-log-forwarding">Red Hat OpenShift Container Platform - Configuring log forwarding</a>.
					</dd></dl></div><section class="section" id="proc-forward-audit-log-splunk_assembly-audit-log"><div class="titlepage"><div><div><h3 class="title">2.1. Forwarding Red Hat Developer Hub audit logs to Splunk</h3></div></div></div><p>
				You can use the Red Hat OpenShift Logging (OpenShift Logging) Operator and a <code class="literal">ClusterLogForwarder</code> instance to capture the streamed audit logs from a Developer Hub instance and forward them to the HTTPS endpoint associated with your Splunk instance.
			</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You have a cluster running on a supported OpenShift Container Platform version.
					</li><li class="listitem">
						You have an account with <code class="literal">cluster-admin</code> privileges.
					</li><li class="listitem">
						You have a Splunk Cloud account or Splunk Enterprise installation.
					</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						Log in to your OpenShift Container Platform cluster.
					</li><li class="listitem"><p class="simpara">
						Install the OpenShift Logging Operator in the <code class="literal">openshift-logging</code> namespace and switch to the namespace:
					</p><div class="formalpara"><p class="title"><strong>Example command to switch to a namespace</strong></p><p>
							
<pre class="programlisting language-bash">oc project openshift-logging</pre>
						</p></div></li><li class="listitem"><p class="simpara">
						Create a <code class="literal">serviceAccount</code> named <code class="literal">log-collector</code> and bind the <code class="literal">collect-application-logs</code> role to the <code class="literal">serviceAccount</code> :
					</p><div class="formalpara"><p class="title"><strong>Example command to create a <code class="literal">serviceAccount</code></strong></p><p>
							
<pre class="programlisting language-bash">oc create sa log-collector</pre>
						</p></div><div class="formalpara"><p class="title"><strong>Example command to bind a role to a <code class="literal">serviceAccount</code></strong></p><p>
							
<pre class="programlisting language-bash">oc create clusterrolebinding log-collector --clusterrole=collect-application-logs --serviceaccount=openshift-logging:log-collector</pre>
						</p></div></li><li class="listitem">
						Generate a <code class="literal">hecToken</code> in your Splunk instance.
					</li><li class="listitem"><p class="simpara">
						Create a key/value secret in the <code class="literal">openshift-logging</code> namespace and verify the secret:
					</p><div class="formalpara"><p class="title"><strong>Example command to create a key/value secret with <code class="literal">hecToken</code></strong></p><p>
							
<pre class="programlisting language-bash">oc -n openshift-logging create secret generic splunk-secret --from-literal=hecToken=&lt;HEC_Token&gt;</pre>
						</p></div><div class="formalpara"><p class="title"><strong>Example command to verify a secret</strong></p><p>
							
<pre class="programlisting language-bash">oc -n openshift-logging get secret/splunk-secret -o yaml</pre>
						</p></div></li><li class="listitem"><p class="simpara">
						Create a basic `ClusterLogForwarder`resource YAML file as follows:
					</p><div class="formalpara"><p class="title"><strong>Example `ClusterLogForwarder`resource YAML file</strong></p><p>
							
<pre class="programlisting language-yaml">apiVersion: logging.openshift.io/v1
kind: ClusterLogForwarder
metadata:
  name: instance
  namespace: openshift-logging</pre>
						</p></div><p class="simpara">
						For more information, see <a class="link" href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.16/html-single/logging/index#logging-create-clf_configuring-log-forwarding">Creating a log forwarder</a>.
					</p></li><li class="listitem"><p class="simpara">
						Define the following <code class="literal">ClusterLogForwarder</code> configuration using OpenShift web console or OpenShift CLI:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								Specify the <code class="literal">log-collector</code> as <code class="literal">serviceAccount</code> in the YAML file:
							</p><div class="formalpara"><p class="title"><strong>Example <code class="literal">serviceAccount</code> configuration</strong></p><p>
									
<pre class="programlisting language-yaml">serviceAccount:
  name: log-collector</pre>
								</p></div></li><li class="listitem"><p class="simpara">
								Configure <code class="literal">inputs</code> to specify the type and source of logs to forward. The following configuration enables the forwarder to capture logs from all applications in a provided namespace:
							</p><div class="formalpara"><p class="title"><strong>Example <code class="literal">inputs</code> configuration</strong></p><p>
									
<pre class="programlisting language-yaml">inputs:
  - name: my-app-logs-input
    type: application
    application:
      includes:
        - namespace: my-rhdh-project
      containerLimit:
        maxRecordsPerSecond: 100</pre>
								</p></div><p class="simpara">
								For more information, see <a class="link" href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.16/html-single/logging/index#cluster-logging-collector-log-forward-logs-from-application-pods_configuring-log-forwarding">Forwarding application logs from specific pods</a>.
							</p></li><li class="listitem"><p class="simpara">
								Configure outputs to specify where the captured logs are sent. In this step, focus on the <code class="literal">splunk</code> type. You can either use <code class="literal">tls.insecureSkipVerify</code> option if the Splunk endpoint uses self-signed TLS certificates (not recommended) or provide the certificate chain using a Secret.
							</p><div class="formalpara"><p class="title"><strong>Example <code class="literal">outputs</code> configuration</strong></p><p>
									
<pre class="programlisting language-yaml">outputs:
  - name: splunk-receiver-application
    type: splunk
    splunk:
      authentication:
        token:
          key: hecToken
          secretName: splunk-secret
      index: main
      url: 'https://my-splunk-instance-url'
      rateLimit:
        maxRecordsPerSecond: 250</pre>
								</p></div><p class="simpara">
								For more information, see <a class="link" href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.16/html-single/logging/index#logging-forward-splunk_configuring-log-forwarding">Forwarding logs to Splunk</a> in OpenShift Container Platform documentation.
							</p></li><li class="listitem"><p class="simpara">
								Optional: Filter logs to include only audit logs:
							</p><div class="formalpara"><p class="title"><strong>Example <code class="literal">filters</code> configuration</strong></p><p>
									
<pre class="programlisting language-yaml">filters:
  - name: audit-logs-only
    type: drop
    drop:
      - test:
        - field: .message
          notMatches: isAuditEvent</pre>
								</p></div><p class="simpara">
								For more information, see <a class="link" href="https://docs.redhat.com/en/documentation/openshift_container_platform/4.16/html-single/logging/index#logging-content-filtering">Filtering logs by content</a> in OpenShift Container Platform documentation.
							</p></li><li class="listitem"><p class="simpara">
								Configure pipelines to route logs from specific inputs to designated outputs. Use the names of the defined inputs and outputs to specify multiple <code class="literal">inputRefs</code> and <code class="literal">outputRefs</code> in each pipeline:
							</p><div class="formalpara"><p class="title"><strong>Example <code class="literal">pipelines</code> configuration</strong></p><p>
									
<pre class="programlisting language-yaml">pipelines:
  - name: my-app-logs-pipeline
    detectMultilineErrors: true
    inputRefs:
      - my-app-logs-input
    outputRefs:
      - splunk-receiver-application
    filterRefs:
      - audit-logs-only</pre>
								</p></div></li></ol></div></li><li class="listitem"><p class="simpara">
						Run the following command to apply the <code class="literal">ClusterLogForwarder</code> configuration:
					</p><div class="formalpara"><p class="title"><strong>Example command to apply <code class="literal">ClusterLogForwarder</code> configuration</strong></p><p>
							
<pre class="programlisting language-bash">oc apply -f &lt;ClusterLogForwarder-configuration.yaml&gt;</pre>
						</p></div></li><li class="listitem"><p class="simpara">
						Optional: To reduce the risk of log loss, configure your <code class="literal">ClusterLogForwarder</code> pods using the following options:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
								Define the resource requests and limits for the log collector as follows:
							</p><div class="formalpara"><p class="title"><strong>Example <code class="literal">collector</code> configuration</strong></p><p>
									
<pre class="programlisting language-yaml">collector:
  resources:
    requests:
      cpu: 250m
      memory: 64Mi
      ephemeral-storage: 250Mi
    limits:
      cpu: 500m
      memory: 128Mi
      ephemeral-storage: 500Mi</pre>
								</p></div></li><li class="listitem"><p class="simpara">
								Define <code class="literal">tuning</code> options for log delivery, including <code class="literal">delivery</code>, <code class="literal">compression</code>, and <code class="literal">RetryDuration</code>. Tuning can be applied per output as needed.
							</p><div class="formalpara"><p class="title"><strong>Example <code class="literal">tuning</code> configuration</strong></p><p>
									
<pre class="programlisting language-yaml">tuning:
  delivery: AtLeastOnce <span id="CO1-1"/><span class="callout">1</span>
  compression: none
  minRetryDuration: 1s
  maxRetryDuration: 10s</pre>
								</p></div><div class="calloutlist"><dl class="calloutlist"><dt><a href="#CO1-1"><span class="callout">1</span></a> </dt><dd><div class="para">
										<code class="literal">AtLeastOnce</code> delivery mode means that if the log forwarder crashes or is restarted, any logs that were read before the crash but not sent to their destination are re-sent. It is possible that some logs are duplicated after a crash.
									</div></dd></dl></div></li></ol></div></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						Confirm that logs are being forwarded to your Splunk instance by viewing them in the Splunk dashboard.
					</li><li class="listitem">
						Troubleshoot any issues using OpenShift Container Platform and Splunk logs as needed.
					</li></ol></div></section></section><section class="section" id="proc-audit-log-view_assembly-audit-log"><div class="titlepage"><div><div><h2 class="title">3. Viewing audit logs in Developer Hub</h2></div></div></div><p>
			Administrators can view, search, filter, and manage the log data from the Red Hat OpenShift Container Platform web console. You can filter audit logs from other log types by using the <code class="literal">isAuditEvent</code> field.
		</p><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
					You are logged in as an administrator in the OpenShift Container Platform web console.
				</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
					From the <span class="strong strong"><strong>Developer</strong></span> perspective of the OpenShift Container Platform web console, click the <span class="strong strong"><strong>Topology</strong></span> tab.
				</li><li class="listitem">
					From the <span class="strong strong"><strong>Topology</strong></span> view, click the pod that you want to view audit log data for.
				</li><li class="listitem">
					From the pod panel, click the <span class="strong strong"><strong>Resources</strong></span> tab.
				</li><li class="listitem">
					From the <span class="strong strong"><strong>Pods</strong></span> section of the <span class="strong strong"><strong>Resources</strong></span> tab, click <span class="strong strong"><strong>View logs</strong></span>.
				</li><li class="listitem">
					From the <span class="strong strong"><strong>Logs</strong></span> view, enter <code class="literal">isAuditEvent</code> into the <span class="strong strong"><strong>Search</strong></span> field to filter audit logs from other log types. You can use the arrows to browse the logs containing the <code class="literal">isAuditEvent</code> field.
				</li></ol></div></section><div><div xml:lang="en-US" class="legalnotice" id="idm46366066143408"><h1 class="legalnotice">Legal Notice</h1><div class="para">
		Copyright <span class="trademark"/>© 2025 Red Hat, Inc.
	</div><div class="para">
		The text of and illustrations in this document are licensed by Red Hat under a Creative Commons Attribution–Share Alike 3.0 Unported license ("CC-BY-SA"). An explanation of CC-BY-SA is available at <a class="uri" href="http://creativecommons.org/licenses/by-sa/3.0/">http://creativecommons.org/licenses/by-sa/3.0/</a>. In accordance with CC-BY-SA, if you distribute this document or an adaptation of it, you must provide the URL for the original version.
	</div><div class="para">
		Red Hat, as the licensor of this document, waives the right to enforce, and agrees not to assert, Section 4d of CC-BY-SA to the fullest extent permitted by applicable law.
	</div><div class="para">
		Red Hat, Red Hat Enterprise Linux, the Shadowman logo, the Red Hat logo, JBoss, OpenShift, Fedora, the Infinity logo, and RHCE are trademarks of Red Hat, Inc., registered in the United States and other countries.
	</div><div class="para">
		<span class="trademark">Linux</span>® is the registered trademark of Linus Torvalds in the United States and other countries.
	</div><div class="para">
		<span class="trademark">Java</span>® is a registered trademark of Oracle and/or its affiliates.
	</div><div class="para">
		<span class="trademark">XFS</span>® is a trademark of Silicon Graphics International Corp. or its subsidiaries in the United States and/or other countries.
	</div><div class="para">
		<span class="trademark">MySQL</span>® is a registered trademark of MySQL AB in the United States, the European Union and other countries.
	</div><div class="para">
		<span class="trademark">Node.js</span>® is an official trademark of Joyent. Red Hat is not formally related to or endorsed by the official Joyent Node.js open source or commercial project.
	</div><div class="para">
		The <span class="trademark">OpenStack</span>® Word Mark and OpenStack logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.
	</div><div class="para">
		All other trademarks are the property of their respective owners.
	</div></div></div></section></div></div><script type="text/javascript">
                        jQuery(document).ready(function() {
                            initSwitchery();
                            jQuery('pre[class*="language-"]').each(function(i, block){hljs.highlightBlock(block);});
                        });
                    </script></body></html>