:_mod-docs-content-type: CONCEPT

[id="con-about-lightspeed-stack-and-llama-stack_{context}"]
= About {lcs-name} and Llama Stack

The **{lcs-name} ({lcs-short})** and Llama Stack deploy together as sidecar containers to augment {rhdh-short} functionality.

{lcs-short} acts as an intermediary service layer for interfacing with Large Language Model (LLM) providers. {lcs-short} handles LLM provider setup, authentication, and includes key functionalities such as question validation, user feedback collection, and Retrieval Augmented Generation (RAG).

Llama Stack provides the model server functionality that {lcs-short} uses to process requests. This service requires a Kubernetes Secret to securely store environment variables for the chosen LLM provider.

The {ls-brand-name} plugin within {rhdh-short} communicates with the {lcs-short} sidecar to send prompts and receives responses from the configured LLM service. The {lcs-short} sidecar centralizes the LLM interaction logic and configuration alongside your {rhdh-short} instance.

[NOTE]
====
{ls-brand-name} is a Developer Preview release. You must manually deploy the {lcs-name} and Llama Stack sidecar containers, and then install the {ls-brand-name} plugin on your {rhdh-short} instance.
====