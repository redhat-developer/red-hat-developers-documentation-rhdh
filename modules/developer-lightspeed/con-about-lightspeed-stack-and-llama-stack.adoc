:_mod-docs-content-type: CONCEPT

[id="con-about-lightspeed-stack-and-llama-stack_{context}"]
= About {lcs-name} and Llama Stack

The {lcs-name} and Llama Stack deploy together as sidecar containers to augment {product-very-short} functionality.

The {lcs-name} serves as the Llama Stack service intermediary, managing configurations for key components. These components include the large language model (LLM) inference providers, Model Context Protocol (MCP) or retrieval augmented generation (RAG) tool runtime providers, safety providers, and vector database settings.

* {lcs-name} manages authentication, user feedback collection, MCP server configuration, and caching.

* Llama Stack provides the inference functionality that {lcs-short} uses to process requests.

* The {ls-brand-name} plugin in {product-very-short} sends prompts and receives LLM responses through the {lcs-short} sidecar. {lcs-short} then uses the Llama Stack sidecar service to perform inference and MCP or RAG tool calling.

[NOTE]
====
{ls-brand-name} is a Developer Preview release. You must manually deploy the {lcs-name} and Llama Stack sidecar containers, and install the {ls-brand-name} plugin on your {product-very-short} instance.
====