:_mod-docs-content-type: CONCEPT

[id="con-about-lightspeed-stack-and-llama-stack_{context}"]
= About {lcs-name} and Llama Stack

The {lcs-name} ({lcs-short}) and Llama Stack deploy together as sidecar containers to augment {rhdh-short} functionality.

{lcs-short} serves as the Llama Stack service intermediary, managing configurations for key components. These components include the Large Language Model (LLM), inference providers, tool runtime providers, safety providers, and Retrieval Augmented Generation (RAG) settings.

* **{lcs-short}** manages authentication, user feedback collection, MCP server configuration, and caching.

* Llama Stack provides the inference functionality that {lcs-short} uses to process requests. The service requires a **Kubernetes Secret** to securely store environment variables for the chosen LLM provider.

* The {ls-brand-name} plugin in {rhdh-short} sends prompts and receives LLM responses through the {lcs-short} sidecar. {lcs-short} then uses the Llama Stack sidecar service to perform inference and MCP tool calling.

[NOTE]
====
{ls-brand-name} is a Developer Preview release. You must manually deploy the {lcs-name} and Llama Stack sidecar containers, and install the {ls-brand-name} plugin on your {rhdh-short} instance.
====