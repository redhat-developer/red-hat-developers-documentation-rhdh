:_mod-docs-content-type: PROCEDURE

[id="proc-installing-and-configuring-lightspeed_{context}"]
= Installing and configuring {ls-brand-name}

{ls-short} includes several components that work together to provide virtual assistant (chat) functionality:

Llama stack server (container sidecar):: Based on open source https://github.com/llamastack/llama-stack[Llama Stack], this service is the gateway to your LLM inferencing provider for chat services. Its modular architecture supports integrating other services, such as Model Context Protocol (MCP). To enable chat functionality, you must integrate your LLM provider with the Llama Stack server using _Bring Your Own Model_ or BYOM.

{lcs-name} ({lcs-short}) (container sidecar):: Based on the open source https://github.com/lightspeed-core[Lightspeed Core], this service extends the Llama Stack server by maintaining chat history and gathering user feedback.

{ls-brand-name} (dynamic plugins):: These plugins enable the {ls-short} user interface within your {product-very-short} instance.

To provide {ls-short} to your users, you must configure these components to communicate with each other. 

[NOTE]
====
* If you are upgrading from the previous {ls-short} Developer Preview with Road-Core Service, you must remove all existing {ls-short} configurations before reinstalling.

* To prevent or resolve upgrade inconsistencies, drop and recreate the dynamic plugins volume.

This reinstallation is required due to the following fundamental architectural changes:

* The previous release used Road-Core Service as a sidecar container for interfacing with LLM providers.

* The updated architecture replaces {rcs-short} with the new {lcs-name} and Llama Stack server, which requires new configurations for the plugins, volumes, containers, and secrets.
====

.Prerequisites

* You are logged in to your {ocp-short} account.
* You have an {product-very-short} instance installed using either the Operator or the Helm chart.
* You have created a {installing-and-viewing-plugins-book-link}#rhdh-installing-rhdh-plugins_title-plugins-rhdh-about[custom dynamic plugins ConfigMap].
* You have administrative access to the {product-very-short} configuration files.

.Procedure

You must manually install and configure the {ls-short} plugin, the {lcs-name} ({lcs-short}) sidecar container, and the Llama Stack sidecar container.

. Create the {lcs-name} ({lcs-short}) ConfigMap to store the service configuration:
.. In the {ocp-short} web console, navigate to your {product-very-short} instance and select the *ConfigMaps* tab.
.. Click *Create ConfigMaps*.
.. Select *YAML view* and edit the file using the following structure. This example demonstrates the configuration for the {lcs-short} ConfigMap, typically named `lightspeed-stack`, which connects to the Llama Stack service locally on port `8321`:
+
[source,yaml]
----
kind: ConfigMap
apiVersion: v1
metadata:
  name: lightspeed-stack
data:
  lightspeed-stack.yaml: |
    name: Lightspeed Core Service (LCS)
    service:
      host: 0.0.0.0
    # Use ${LIGHTSPEED_SERVICE_PORT} if you are not running the Service on port `8080`
    # port: ${LIGHTSPEED_SERVICE_PORT}
      auth_enabled: false
      workers: 1
      color_log: true
      access_log: true
    llama_stack:
      use_as_library_client: false
      url: http://localhost:8321
    user_data_collection:
      feedback_enabled: true
      feedback_storage: "/tmp/data/feedback"
      transcripts_enabled: true
      transcripts_storage: "/tmp/data/transcripts"
    authentication:
      module: "noop"
    conversation_cache:
      type: "sqlite"
      sqlite:
        db_path: "/tmp/data/conversations/lcs_cache.db"
----
+
[IMPORTANT]
====
LCS uses Llama Stack expansion syntax for environment variables. To make sure the service correctly parses variables in the `lightspeed-stack.yaml` file, you must use the `${env.VAR}` format. Variable names are case-sensitive and must be uppercase. The syntax `${env.var}` is not supported. For example:
[source,yaml]
----
model_config:
  api_key: ${env.VAR}
----
====
.. Click *Create*.

. Create the {ls-short}  ConfigMap (`lightspeed-app-config`) for plugin configurations:
.. In the {ocp-short} web console, navigate to your {product-very-short} instance and select the *ConfigMaps* tab.
.. Click *Create ConfigMap*.
.. Select the *YAML view* option and add the following configuration:
+
[source,yaml]
----
kind: ConfigMap
apiVersion: v1
metadata:
  name: lightspeed-app-config
  namespace: <__namespace__> # Enter your RHDH instance namespace
data:
  app-config.yaml: |-
    backend:
      csp:
        upgrade-insecure-requests: false
      img-src:
        - "'self'"
        - "data:"
        - https://img.freepik.com
        - https://cdn.dribbble.com
        - https://avatars.githubusercontent.com # This is to load GitHub avatars in the UI
        script-src:
        - "'self'"
        - "'unsafe-eval'"
        - https://cdn.jsdelivr.net

    lightspeed:
      # OPTIONAL: Custom users prompts displayed to users
      # If not provided, the plugin uses built-in default prompts
      prompts:
        - title: `Getting Started with Red Hat Developer Hub`
          message: Can you guide me through the first steps to start using {product-short} as a developer, like exploring the Software Catalog and adding my service?

      # OPTIONAL: Port for lightspeed service (default: 8080)
      # servicePort: ${LIGHTSPEED_SERVICE_PORT}

      # OPTIONAL: Override default RHDH system prompt
      # systemPrompt: "You are a helpful assistant focused on Red Hat Developer Hub development."
----
.. Click *Create*.

. Create Llama Stack Secret file (`llama-stack-secrets`) for LLM provider credentials:
+
[IMPORTANT]
====
{product} {product-version} configures the Llama Stack image to use the vLLM provider exclusively. The vLLM provider supports the OpenAI API schema but does not support connecting directly to the official OpenAI service (`api.openai.com`).
Do not use the official OpenAI API URL or token with vLLM in this release. Attempting this might result in errors or improper responses. Native OpenAI provider support is planned for future releases.
====

.. In the {ocp-short} web console, navigate to *Secrets*.
.. Click *Create* -> *Key/value secret*.
.. Select the *YAML view* option and add the following structure:
+
[source,yaml]
----
apiVersion: v1
kind: Secret
metadata:
  name: llama-stack-secrets
type: Opaque
stringData:
  ENABLE_VLLM: "true"
  ENABLE_VERTEX_AI: ""
  ENABLE_OPENAI: ""
  ENABLE_OLLAMA: ""
  VLLM_URL: "_<api_endpoint>_"
  VLLM_API_KEY: "_<api_key>_"
  VLLM_MAX_TOKENS: ""
  VLLM_TLS_VERIFY: ""
  OPENAI_API_KEY: ""
  VERTEX_AI_PROJECT: ""
  VERTEX_AI_LOCATION: ""
  GOOGLE_APPLICATION_CREDENTIALS: ""
  OLLAMA_URL: ""
  SAFETY_MODEL: "llama-guard3:8b"
  SAFETY_URL: "http://localhost:#####/v1"
  SAFETY_API_KEY: ""
----
+
where:

`ENABLE_VLLM`:: Enables the vLLM provider. Set to true to activate.
`ENABLE_OPENAI`:: Enables the OpenAI provider. Set to true to activate.
`ENABLE_VERTEX_AI`:: Enables the Vertex AI provider. Set to true to activate.
`ENABLE_OLLAMA`:: Enables the Ollama provider. Set to true to activate.
[NOTE]
====
To disable a provider, leave the value blank. (for example: ENABLE_VLLM="")
====
`VLLM_URL`:: The API endpoint URL for the LLM provider. The provider must comply with the OpenAI API specification. Examples include OpenAI, {rhoai-brand-name}, and vLLM.
`VLLM_API_KEY`:: Required for remote services: Set this to the API key or token required for authentication with your remote LLM provider, if it is compatible with the OpenAI API specification. 
`VLLM_MAX_TOKENS`:: Optional. The maximum number of tokens the model generates.
`VLLM_TLS_VERIFY`:: Optional. Specifies whether the system verifies the TLS certificate for the vLLM endpoint.
`OPENAI_API_KEY`:: The API key required to access OpenAI models through the OpenAI API.
`VERTEX_AI_PROJECT`:: The Google Cloud project ID required to access Gemini through Vertex AI.
`VERTEX_AI_LOCATION`:: The Google Cloud region required to access Gemini through Vertex AI.
`GOOGLE_APPLICATION_CREDENTIALS`:: The credentials required to authenticate with Google Cloud to access Vertex AI.
`OLLAMA_URL`:: The URL for the Ollama service.
`SAFETY_MODEL`:: The identifier for the safety model. The recommended value is llama-guard3:8b.
`SAFETY_URL`:: The URL hosting the safety model. You must append `/v1` to the host address (for example: `localhost:#####/v1`).
`SAFETY_API_KEY`:: The API key required to authenticate with the safety model, if applicable.
.. Click *Create*.

. Update the dynamic plugins ConfigMap: Add the {ls-short} plugin image to your existing dynamic plugins ConfigMap (`dynamic-plugins-rhdh`).
+
[source,yaml]
----
includes:
- dynamic-plugins.default.yaml
plugins:
- disabled: false
  package: oci://ghcr.io/redhat-developer/rhdh-plugin-export-overlays/red-hat-developer-hub-backstage-plugin-lightspeed:bs_1.45.3__1.2.3
  pluginConfig:
    dynamicPlugins:
      frontend:
        red-hat-developer-hub.backstage-plugin-lightspeed:
              translationResources:
                - importName: lightspeedTranslations
                  module: Alpha
                  ref: lightspeedTranslationRef
              dynamicRoutes:
                - path: /lightspeed
                  importName: LightspeedPage
              mountPoints:
                - mountPoint: application/listener
                  importName: LightspeedFAB
                - mountPoint: application/provider
                  importName: LightspeedDrawerProvider
                - mountPoint: application/internal/drawer-state
                  importName: LightspeedDrawerStateExposer
                  config:
                    id: lightspeed
                - mountPoint: application/internal/drawer-content
                  importName: LightspeedChatContainer
                  config:
                    id: lightspeed
                    priority: 100
- disabled: false
  package: oci://ghcr.io/redhat-developer/rhdh-plugin-export-overlays/red-hat-developer-hub-backstage-plugin-lightspeed-backend:bs_1.45.3__1.2.3
----

. Required only if your environment uses another global floating action button (FAB): You must move the existing FAB or disable it to prevent interface elements from overlapping by updating your dynamic plugin configuration file with the following changes:
+
[source,yaml]
----
- package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import
  disabled: true
  pluginConfig:
    dynamicPlugins:
      frontend:
        red-hat-developer-hub.backstage-plugin-bulk-import:
          mountPoints:
          # START: If the user has an existing BulkImportPage FAB, move the FAB to the left
            - mountPoint: global.floatingactionbutton/config
              importName: BulkImportPage
              config:
                slot: 'bottom-left'
          # END
                icon: BulkImportIcon
                label: 'Bulk import'
                toolTip: 'Register multiple repositories in bulk'
                to: /bulk-import
          translationResources:
          - importName: bulkImportTranslations
            module: Alpha
            ref: bulkImportTranslationRef
          appIcons:
          - name: bulkImportIcon
            importName: BulkImportIcon
          dynamicRoutes:
          - path: /bulk-import
            importName: BulkImportPage
            menuItem:
              icon: bulkImportIcon
              text: Bulk import
              textKey: menuItem.bulkImport
----

. Update your deployment configuration: Update the deployment configuration based on how your {product-very-short} instance was installed. You must add two sidecar containers: `llama-stack` and `lightspeed-core`.

** For an Operator-installed {product-very-short} instance (Update {backstage} custom resource (CR)):

... In the `spec.application.appConfig.configMaps` section of your {backstage} CR, add the {ls-short} custom app configuration:
+
[source,yaml]
----
appConfig:
  configMaps:
    - name: lightspeed-app-config
----
... Update the `spec.deployment.patch.spec.template.spec.volumes` specification to include volumes for {lcs-short} configuration (`lightspeed-stack`), shared storage for feedback (`shared-storage`), and RAG data (`rag-data-volume`):
+
[source,yaml]
----
volumes:
  - configMap:
      name: lightspeed-stack
    name: lightspeed-stack
  - emptyDir: {}
    name: shared-storage
  - emptyDir: {}
    name: rag-data-volume
----
... Add the `initContainers` section to initialize RAG data:
[source,yaml]
+
----
initContainers:
  - name: init-rag-data
    image: 'quay.io/redhat-ai-dev/rag-content:release-1.9-lcs'
    command:
      - "sh"
      - "-c"
      - "echo 'Copying RAG data...'; cp -r /rag/vector_db/rhdh_product_docs /rag-content/ && cp -r /rag/embeddings_model /rag-content/ && echo 'Copy complete.'"
    volumeMounts:
      - mountPath: /rag-content
        name: rag-data-volume
----
... Add the Llama Stack and the {lcs-short} containers to the `spec.deployment.patch.spec.template.spec.containers` section:
+
[source,yaml]
----
containers:
  # ... Your existing RHDH container definition ...
  - envFrom:
      - secretRef:
          name: llama-stack-secrets
    image: 'quay.io/redhat-ai-dev/llama-stack:0.1.4' # Llama Stack image
    name: llama-stack
    volumeMounts:
      - mountPath: /app-root/.llama
        name: shared-storage
      - mountPath: /rag-content
        name: rag-data-volume
  - image: 'quay.io/lightspeed-core/lightspeed-stack:0.4.0' # Lightspeed Core Service image
    name: lightspeed-core
    volumeMounts:
      - mountPath: /app-root/lightspeed-stack.yaml
        name: lightspeed-stack
        subPath: lightspeed-stack.yaml
      - mountPath: /tmp/data/feedback
        name: shared-storage
      - mountPath: /tmp/data/transcripts
        name: shared-storage
      - mountPath: /tmp/data/conversations
        name: shared-storage
----
... Click *Save*. The Pods are automatically restarted.

** For a Helm-installed {product-very-short} instance (Update the Helm chart):

... Add your dynamic plugins configuration in the `global.dynamic` property.
+
[source,yaml]
----
global:
  dynamic:
    plugins:
      - package: oci://ghcr.io/redhat-developer/rhdh-plugin-export-overlays/red-hat-developer-hub-backstage-plugin-lightspeed:bs_1.45.3__1.2.3
        pluginConfig:
        dynamicPlugins:
          frontend:
            red-hat-developer-hub.backstage-plugin-lightspeed:
                  translationResources:
                    - importName: lightspeedTranslations
                      module: Alpha
                      ref: lightspeedTranslationRef
                  dynamicRoutes:
                    - path: /lightspeed
                      importName: LightspeedPage
                  mountPoints:
                    - mountPoint: application/listener
                      importName: LightspeedFAB
                    - mountPoint: application/provider
                      importName: LightspeedDrawerProvider
                    - mountPoint: application/internal/drawer-state
                      importName: LightspeedDrawerStateExposer
                      config:
                        id: lightspeed
                    - mountPoint: application/internal/drawer-content
                      importName: LightspeedChatContainer
                      config:
                        id: lightspeed
                        priority: 100
      - package: oci://ghcr.io/redhat-developer/rhdh-plugin-export-overlays/red-hat-developer-hub-backstage-plugin-lightspeed-backend:bs_1.45.3__1.2.3
----
... Add your {ls-short} custom app config file to `extraAppConfig`:
+
[source,yaml]
----
    extraAppConfig:
      - configMapRef: lightspeed-app-config
        filename: app-config.yaml
----
... Add the Llama Stack Secret file to `extraEnvVarsSecrets`:
+
[source,yaml]
----
    extraEnvVarsSecrets:
      - llama-stack-secrets
----
... Update the `extraVolumes` section to include the {lcs-short} ConfigMap (`lightspeed-stack`), shared storage, and RAG data volume:
+
[source,yaml]
----
    extraVolumes:
      - configMap:
          name: lightspeed-stack
        name: lightspeed-stack
      - emptyDir: {}
        name: shared-storage
      - emptyDir: {}
        name: rag-data-volume
----
... Update the `initContainers` section (if supported by your Helm chart structure) to initialize RAG data.
+
[source,yaml]
----
  initContainers:
      - name: init-rag-data
        image: 'quay.io/redhat-ai-dev/rag-content:release-1.9-lcs'
        command:
          - "sh"
          - "-c"
          - "echo 'Copying RAG data...'; cp -r /rag/vector_db/rhdh_product_docs /data/ && cp -r /rag/embeddings_model /data/ && echo 'Copy complete.'"
        volumeMounts:
          - mountPath: /data
            name: rag-data-volume
----
... Add the Llama Stack and {lcs-short} container definitions to `extraContainers`.
+
[NOTE]
====
If you have Road-Core Service installed from the previous {ls-brand-name} configuration, you must replace the older single container configuration found in source with the two sidecars.
====
+
[source, yaml]
----
    extraContainers:
      # Llama Stack Container
      - envFrom:
          - secretRef:
              name: llama-stack-secrets
        image: 'quay.io/redhat-ai-dev/llama-stack:0.1.4'
        name: llama-stack
        volumeMounts:
          - mountPath: /app-root/.llama
            name: shared-storage
          - mountPath: /app-root/embeddings_model
            name: rag-data-volume
            subPath: embeddings_model
          - mountPath: /app-root/vector_db/rhdh_product_docs
            name: rag-data-volume
            subPath: rhdh_product_docs
      # Lightspeed Core Service Container
      - image: 'quay.io/lightspeed-core/lightspeed-stack:0.4.0'
        name: lightspeed-core
        volumeMounts:
          - mountPath: /app-root/lightspeed-stack.yaml
            name: lightspeed-stack
            subPath: lightspeed-stack.yaml
          - mountPath: /tmp/data/feedback
            name: shared-storage
          - mountPath: /tmp/data/transcripts
            name: shared-storage
          - mountPath: /tmp/data/conversations
            name: shared-storage
----
... Click *Save* and then Helm upgrade.

. Optional: Manage authorization (RBAC): If you have users who are not administrators, you must {authorization-book-link}#enabling-and-giving-access-to-rbac[define permissions and roles] for them to use {ls-short}. The Lightspeed Backend plugin uses {backstage} RBAC for authorization.

** For an Operator-installed {product-very-short} instance:

... Configure the required RBAC permission by defining an `rbac-policies.csv` file, including `lightspeed.chat.read`, `lightspeed.chat.create`, and `lightspeed.chat.delete` permissions:
+
[source,csv]
----
p, role:default/_<your_team>_, lightspeed.chat.read, read, allow
p, role:default/_<your_team>_, lightspeed.chat.create, create, allow
p, role:default/_<your_team>_, lightspeed.chat.delete, delete, allow
g, user:default/_<your_user>_, role:default/_<your_team>_
----
... Upload your `rbac-policies.csv` file to an `rbac-policies` ConfigMap in your {ocp-short} project containing {product-very-short} and update your {backstage} CR:
+
[source,yaml]
----
apiVersion: rhdh.redhat.com/v1alpha5
kind: Backstage
spec:
  application:
    extraFiles:
      mountPath: /opt/app-root/src
      configMaps:
        - name: rbac-policies
----

** For a Helm-installed {product-very-short} instance:

... Configure the required RBAC permission by defining an `rbac-policies.csv` file:
+
[source,csv]
----
p, role:default/_<your_team>_, lightspeed.chat.read, read, allow
p, role:default/_<your_team>_, lightspeed.chat.create, create, allow
p, role:default/_<your_team>_, lightspeed.chat.delete, delete, allow
g, user:default/_<your_user>_, role:default/_<your_team>_
----
... Optional: Declare policy administrators by editing your custom {product-very-short} ConfigMap (`app-config.yaml`) and adding the following code to enable selected authenticated users to configure RBAC policies through the REST API or Web UI:
+
[source,yaml]
----
  permission:
    enabled: true
    rbac:
      policies-csv-file: /opt/app-root/src/rbac-policies.csv
      policyFileReload: true
    admin:
      users:
        - name: user:default/<your_policy_administrator_name>
----

.Verification

. Log in to your {product-very-short} instance.
. Verify that you can see and access the *Lightspeed* FAB in the home page.
. Select the *Lightspeed* FAB and verify the chat screen loads.
