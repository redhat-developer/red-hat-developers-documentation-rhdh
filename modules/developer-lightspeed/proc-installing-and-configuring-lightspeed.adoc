:_mod-docs-content-type: PROCEDURE

[id="proc-installing-and-configuring-lightspeed_{context}"]
= Installing and configuring {ls-brand-name}

You must install and configure the {ls-short}, {lcs-short}, and Llama Stack container manually.

.Prerequisites
* You are logged into your {ocp-short} account.
* You have an {product-very-short} instance installed either of the following ways:
** {installing-on-ocp-book-link}#assembly-install-rhdh-ocp-operator[Using the Operator]
** {installing-on-ocp-book-link}#assembly-install-rhdh-ocp-helm[Using the Helm chart]

.Procedure

. Create the {lcs-short} ConfigMap (`lightspeed-stack.yaml`).
.. In the {ocp-short} web console, go to your {product-very-short} instance and select the *ConfigMaps* tab.
.. Click *Create ConfigMaps*.
.. From the *Create ConfigMap* page, select the *YAML view* option in *Configure via*, and edit the file as shown in the following example:
+
[source,yaml]
----
kind: ConfigMap
apiVersion: v1
metadata:
 name: Lightspeed Core Service (LCS)
service:
  host: 0.0.0.0
  port: 8080
  auth_enabled: false
  workers: 1
  color_log: true
  access_log: true
llama_stack:
  use_as_library_client: false
  url: http://localhost:8321
user_data_collection:
  feedback_enabled: true
  feedback_storage: "/tmp/data/feedback"
  transcripts_enabled: true
  transcripts_storage: "/tmp/data/transcripts"
authentication:
  module: "noop"
conversation_cache:
  type: "sqlite"
  sqlite:
    db_path: "./lcs_cache.db"
mcp_servers:
  - name: mcp::backstage
    provider_id: model-context-protocol
    url: https://rhdh-mcp-proxy-apicast-production.apps.rosa.redhat-ai-dev.m6no.p3.openshiftapps.com:443/api/mcp-actions/v1
----
where:
`mcp_servers:name`:: This value must match the entry in the {ls-short} app config file for MCP servers.

.. Click *Create*.

. Create a Llama Stack ConfigMap.
.. In the {ocp-short} web console, go to your {product-very-short} instance and select the *ConfigMaps* tab.
.. Click *Create ConfigMaps*.
.. From the *Create ConfigMap* page, select the *YAML view* option in *Configure via*, and edit the file as shown in the following example:
+
[source,yaml]
----
models:
  - model_id: sentence-transformers/all-mpnet-base-v2
    metadata:
      embedding_dimension: 768
    model_type: embedding
    provider_id: sentence-transformers
    provider_model_id: "/app-root/embeddings_model"
providers:
  inference:
  - provider_id: team-cluster
    provider_type: remote::vllm
    config:
      url: _<llm-server>_/v1
      api-token: <token>
  - provider_id: openai
    provider_type: remote::openai
    config:
      api_key: _<openai_api_key>_
----
where:
`_<llm_server>_`:: Enter your LLM server details.
`_<openai_api_key>_`:: Enter your OpenAI API key.

. Create the {ls-short} ConfigMap.
+
[NOTE]
====
Create a dedicated {ls-short} ConfigMap instead of adding an additional section to your existing {product-very-short} custom application configuration file (for example, `lightspeed-app-config.yaml`). Creating two files prevents the entire {product-very-short} ConfigMap from being loaded into {lcs-short}.
====
.. In the {ocp-short} web console, go to your {product-very-short} instance and select the *ConfigMaps* tab.
.. Click *Create ConfigMap*.
.. From the *Create ConfigMap* page, select the *YAML view* option in *Configure via*, and add the following example:
+
[source,yaml,subs="+attributes"]
----
kind: ConfigMap
apiVersion: v1
metadata:
  name: lightspeed-app-config
  namespace: <__namespace__> # Enter your {product-very-short} instance namespace
data:
  app-config.yaml: |-
    backend:
      csp:
         upgrade-insecure-requests: false
       img-src:
          - "'self'"
          - "data:"
          - https://img.freepik.com
          - https://cdn.dribbble.com
          - https://avatars.githubusercontent.com # This is to load GitHub avatars in the UI
       script-src:
           - "'self'"
           - https://cdn.jsdelivr.net

    lightspeed:
      mcpServers:
      - name: mcp::backstage
        token: ${MCP_TOKEN} 

      # OPTIONAL: Enable/disable question validation (default: true)
      # When enabled, restricts questions to RHDH-related topics for better security
      questionValidation: true

      # OPTIONAL: Custom users prompts displayed to users
      # If not provided, the plugin uses built-in default prompts
      prompts:
        - title: 'Getting Started with {product}'
          message: Can you guide me through the first steps to start using {product-short} as a developer, like exploring the Software Catalog and adding my service?

      # OPTIONAL: Port for lightspeed service (default: 8080)
      # servicePort: ${LIGHTSPEED_SERVICE_PORT}

      # OPTIONAL: Override default RHDH system prompt
      # systemPrompt: "You are a helpful assistant focused on {product} development."
----
. Create {ls-short} secret file.
.. In the {ocp-short} web console, go to *Secrets*.
.. Click *Create > Key/value secret*.
.. In the *Create key/value secret* page, select the *YAML view* option in *Configure via*, and add the following example:
+
[source,yaml]
----
kind: Secret
apiVersion: v1
metadata:
  name: lightspeed-secrets
  namespace: _<namespace>_ # Enter your rhdh instance namespace
stringData:
  LLM_SERVER_ID: _<server_id>_ # Enter your server ID (for example, `ollama` or `granite`)
  LLM_SERVER_TOKEN: _<token>_ # Enter your server token value
  LLM_SERVER_URL: _<server_url>_ # Enter your server URL
type: Opaque
----
.. Click *Create*.

. Create the Llama Stack secret file.
.. In the {ocp-short} web console, go to *Secrets*.
.. Click *Create > Key/value secret*.
.. In the *Create key/value secret* page, select the *YAML view* option in *Configure via*, and add the following example:
+
[source,yaml]
----
apiVersion: v1
kind: Secret
metadata:
    name: llama-stack-secrets
type: Opaque
stringData:
    VLLM_URL: "" # Set this if you are using redhat-ai-dev Llama Stack image
    VLLM_API_KEY: "" # Set this if you are using redhat-ai-dev Llama Stack
    VLLM_MAX_TOKENS: "" # Optional
    VLLM_TLS_VERIFY: "" # Optional
    OLLAMA_URL: "" # Set if you altered the run.yaml to use it
    OPENAI_API_KEY: "" # Set if you altered the run.yaml to use it
    VALIDATION_PROVIDER: "" # One of vllm, ollama, openai depending on above
    VALIDATION_MODEL_NAME: "" # Name of model you want used for validation
----
.. Click *Create*.

. To your existing dynamic plugins ConfigMap (for example, `dynamic-plugins-rhdh.yaml`), add the {ls-short} plugin image as shown in the following example:
+
[source,yaml,subs="+attributes"]
----
includes:
  - dynamic-plugins.default.yaml
 plugins:
  - package: oci://ghcr.io/redhat-developer/rhdh-plugin-export-overlays/red-hat-developer-hub-backstage-plugin-lightspeed:bs_1.39.1__0.5.7!red-hat-developer-hub-backstage-plugin-lightspeed
    disabled: false
    pluginConfig:
      lightspeed:
        # OPTIONAL: Custom users prompts displayed to users
        # If not provided, the plugin uses built-in default prompts
        prompts:
          - title: 'Getting Started with {product}'
            message: Can you guide me through the first steps to start using {product-short}
              as a developer, like exploring the Software Catalog and adding my
              service?
      dynamicPlugins:
        frontend:
          red-hat-developer-hub.backstage-plugin-lightspeed:
            appIcons:
              - name: LightspeedIcon
                module: LightspeedPlugin
                importName: LightspeedIcon
            dynamicRoutes:
              - path: /lightspeed
                importName: LightspeedPage
                module: LightspeedPlugin
                menuItem:
                  icon: LightspeedIcon
                  text: Lightspeed
  - package: oci://ghcr.io/redhat-developer/rhdh-plugin-export-overlays/red-hat-developer-hub-backstage-plugin-lightspeed-backend:bs_1.39.1__0.5.7!red-hat-developer-hub-backstage-plugin-lightspeed-backend
    disabled: false
    pluginConfig:
      lightspeed:
        # REQUIRED: Configure LLM servers with OpenAI API compatibility
        servers:
          - id: ${LLM_SERVER_ID}
            url: ${LLM_SERVER_URL}
            token: ${LLM_SERVER_TOKEN}

        # OPTIONAL: Port for lightspeed service (default: 8080)
        # servicePort: ${LIGHTSPEED_SERVICE_PORT}
----

. Update your deployment configuration based on your installation method:
.. For an Operator-installed {product-very-short} instance, update your {product-custom-resource-type} custom resource (CR).
... In the `spec.application.appConfig.configMaps` section, add the {ls-short} and Llama Stack custom app configurations as shown in the following example:
+
[source,yaml]
----
      appConfig:
        configMaps:
          - name: lightspeed-app-config
        mountPath: /opt/app-root/src
        configMaps:
          - name: llama-stack
        mountPath: /opt/app-root/src
----
... Update the `extraVolumes` specification to include the {lcs-short} and Llama Stack ConfigMaps as shown in the following example:
+
[source,yaml]
----
            volumes:
              - configMap:
                  name: lightspeed-stack
              - configMap:
                  name: llama-stack
----
... Update the `volumeMounts` specification to mount the {lcs-short} and Llama Stack ConfigMaps as shown in the following example:
+
[source,yaml]
----
        volumeMounts:
          - mountPath: /app-root/config/lightspeed-stack.yaml
            name: lightspeed-stack
            subPath: lightspeed-stack.yaml
          - mountPath: /app-root/config/app-config-rhdh.yaml
            name: lightspeed-app-config
            subPath: app-config.yaml
          - mountPath: /app-root-config/llama-stack/run.yaml
            subPath: llama-stack/run.yaml
----
... Add the {ls-short} and Llama Stack Secret file as shown in the following example:
+
[source,yaml]
----
        envFrom:
          - secretRef:
              name: lightspeed-secrets
          - secretRef:
              name: llama-stack-secrets
----
... In your `deployment.patch.spec.template.spec.containers.env` section, set the {lcs-short} and Llama Stack environment variables as shown in the following example:
+
[source,yaml]
----
    - name: PROJECT
      value: rhdh
    - name: LCS_CONFIG_FILE
      value: /app-root/config/lightspeed-stack.yaml
    - name: RHDH_CONFIG_FILE
      value: /app-root/config/app-config-rhdh.yaml
    - name: LLAMA_CONFIG_FILE
      value: /app-root/config/llama-stack/run.yaml
----
+
[NOTE]
====
Your {product-very-short} container is typically already present in your CR. You are adding the two additional container definitions for {lcs-short} and Llama Stack as the {lcs-short} sidecar.
====
... Click *Save*. The Pods are automatically restarted.
+
.Example of a Backstage CR with the {lcs-short} container
[source,yaml,subs=+attributes]
----
kind: Backstage
metadata:
...
name: name
namespace: namespace
spec:
 deployment:
   patch:
     spec:
       template:
         spec:
           initContainers:
             - name: init-rag-data
               image: 'quay.io/redhat-ai-dev/rag-content:release-1.7-lcs'
               command:
                 - "sh"
                 - "-c"
                 - "echo 'Copying RAG data...'; cp -r /rag/vector_db/rhdh_product_docs /data/ && cp -r /rag/embeddings_model /data/ && echo 'Copy complete.'"
               volumeMounts:
                 - mountPath: /data
                   name: rag-data-volume
           containers:
             - envFrom:
               - secretRef:
                   name: llama-stack-secrets
               image: 'quay.io/redhat-ai-dev/llama-stack:latest'
               name: llama-stack
               volumeMounts:
                 - mountPath: /app-root/.llama
                   name: shared-storage
                 - mountPath: /app-root/embeddings_model
                   name: rag-data-volume
                   subPath: embeddings_model
                 - mountPath: /app-root/vector_db/rhdh_product_docs
                   name: rag-data-volume
                   subPath: rhdh_product_docs
             - image: <your-lcs-image>
               name: lightspeed-core
               volumeMounts:
                 - mountPath: /app-root/lightspeed-stack.yaml
                   name: lightspeed-stack
                   subPath: lightspeed-stack.yaml
                 - mountPath: /tmp/data/feedback
                   name: shared-storage
           volumes:
             - configMap:
                 name: lightspeed-stack
               name: lightspeed-stack
             - emptyDir: {}
               name: shared-storage
             - emptyDir: {}
               name: rag-data-volume
----
.. For a Helm-installed {product-very-short} instance, update your Helm chart.
... Add your dynamic plugins configuration in the`global.dynamic` property as shown in the following example:
+
[source,yaml,subs="+attributes"]
----
global:
dynamic:
  includes:
  - dynamic-plugins.default.yaml
  plugins:
  - package: oci://ghcr.io/redhat-developer/rhdh-plugin-export-overlays/red-hat-developer-hub-backstage-plugin-lightspeed:bs_1.39.1__0.5.7!red-hat-developer-hub-backstage-plugin-lightspeed
    disabled: false
    pluginConfig:
      lightspeed:
        # OPTIONAL: Custom users prompts displayed to users
        # If not provided, the plugin uses built-in default prompts
        prompts:
          - title: 'Getting Started with {product}'
            message: Can you guide me through the first steps to start using {product-short}
              as a developer, like exploring the Software Catalog and adding my
              service?
      dynamicPlugins:
        frontend:
          red-hat-developer-hub.backstage-plugin-lightspeed:
            appIcons:
              - name: LightspeedIcon
                module: LightspeedPlugin
                importName: LightspeedIcon
            dynamicRoutes:
              - path: /lightspeed
                importName: LightspeedPage
                module: LightspeedPlugin
                menuItem:
                  icon: LightspeedIcon
                  text: Lightspeed
  - package: oci://ghcr.io/redhat-developer/rhdh-plugin-export-overlays/red-hat-developer-hub-backstage-plugin-lightspeed-backend:bs_1.39.1__0.5.7!red-hat-developer-hub-backstage-plugin-lightspeed-backend
    disabled: false
    pluginConfig:
      lightspeed:
        # REQUIRED: Configure LLM servers with OpenAI API compatibility
        servers:
          - id: ${LLM_SERVER_ID}
            url: ${LLM_SERVER_URL}
            token: ${LLM_SERVER_TOKEN}
        # OPTIONAL: Port for lightspeed service (default: 8080)
        # servicePort: ${LIGHTSPEED_SERVICE_PORT}
----
... Add your {ls-short} custom app config file as shown in the following example:
+
[source,yaml]
----
 extraAppConfig:
      - configMapRef: lightspeed-app-config
        filename: app-config.yaml
----
... Update the `extraVolumes` section to include the {lcs-short} ConfigMap as shown in the following example:
+
[source,yaml]
----
extraVolumes:
      - configMap:
          name: /app-root/config/lightspeed-stack.yaml
        name: lightspeed-stack
----
... Update the `extraVolumeMounts` section to mount the {lcs-short} and Llama Stack ConfigMap as shown in the following example:
+
[source,yaml]
----
 extraVolumeMounts:
      - mountPath: /app-root/config/lightspeed-stack.yaml
        name: lightspeed-stack
----
... Add the {ls-short} and Llama Stack Secret file as shown in the following example:
+
[source,yaml]
----
 extraEnvVarsSecrets:
      - lightspeed-secrets
----
... Add the {lcs-short} image as shown in the following example:
+
[source,yaml,subs="+attributes"]
----
   extraContainers:
      - env:
          - name: PROJECT
            value: rhdh
          - name: LCS_CONFIG_FILE
            value: /app-root/config/lightspeed-stack.yaml
          - name: RHDH_CONFIG_FILE
            value: /app-root/config/lightspeed-app-config.yaml
        envFrom:
          - secretRef:
              name: lightspeed-secrets
        image: 'quay.io/redhat-ai-dev/llama-stack:latest'
        name: road-core-sidecar
        ports:
          - containerPort: 8080
            name: lcs-backend
            protocol: TCP
        volumeMounts:
          - mountPath: /app-root/config/lightspeed-stack.yaml
            name: lightspeed-stack
            subPath: lightspeed-stack.yaml
          - mountPath: /app-root/config/lightspeed-app-config.yaml
            name: lightspeed-app-config
            subPath: app-config.yaml
          - mountPath: /app-root/run.yaml
            name: llama-stack-config
            subPath: run.yaml
----
+
[NOTE]
====
Your {product-very-short} container is typically already present in your Helm chart. You are adding the two additional container definitions for {lcs-short} and Llama Stack as the {lcs-short} sidecar.
====
... Click *Save*.
... Click *Helm upgrade*.
+
.Example of a Helm chart with the LCS and Llama Stack container
[source,yaml,subs="+attributes"]
----
global:
 ...
upstream:
 backstage:
   appConfig:
     ...
   args:
     ...
   extraAppConfig:
     - configMapRef: lightspeed-app-config
       filename: app-config.yaml
     - configMapRef: llama-stack-config
       filename: run.yaml
   extraContainers:
     - env:
         - name: PROJECT
           value: rhdh
         - name: LCS_CONFIG_FILE
           value: /app-root/config/lcsconfig.yaml
         - name: LLAMA_STACK_CONFIG_FILE
           value: /app-root/run.yaml
         - name: RHDH_CONFIG_FILE
           value: /app-root/config/lightspeed-app-config.yaml
       envFrom:
         - secretRef:
             name: lightspeed-secrets
       image: 'quay.io/redhat-ai-dev/llama-stack:latest'
       name: lightspeed-core-sidecar
       ports:
         - containerPort: 8080
           name: lcs-backend
           protocol: TCP
       volumeMounts:
         - mountPath: /app-root/config/lightspeed-stack.yaml
           name: lightspeed-stack
           subPath: lightspeed-stack.yaml
         - mountPath: /app-root/run.yaml
           name: llama-stack-config
           subPath: run.yaml
         - mountPath: /app-root/config/lightspeed-app-config.yaml
           name: lightspeed-app-config
           subPath: lightspeed-app-config.yaml
   extraEnvVars:
     ...
   extraEnvVarsSecrets:
     - lightspeed-secrets
   extraVolumeMounts:
     - mountPath: /app-root/config/lightspeed-stack.yaml
       name: lightspeed-stack
     - mountPath: /app-root/run.yaml
       name: llama-stack-config
   extraVolumes:
     - configMap:
         name: lightspeed-stack
       name: lightspeed-stack
     ...
   image:
     ...
   initContainers:
     ...
----

. Define permissions and roles for your users who are not administrators by completing the following steps:
.. Configure the required RBAC permission by defining an `rbac-policies.csv` file as shown in the following example:
+
[source,yaml]
----
p, role:default/_<your_team>_, lightspeed.chat.read, read, allow
p, role:default/_<your_team>_, lightspeed.chat.create, create, allow
p, role:default/_<your_team>_, lightspeed.chat.delete, delete, allow

g, user:default/_<your_user>_, role:default/_<your_team>_
----
.. Upload your `rbac-policies.csv` and `rbac-conditional-policies.yaml` files to an `rbac-policies` config map in your {ocp-short} project containing {product-very-short}.
.. Update your {product-custom-resource-type} custom resource to mount in the {product-very-short} filesystem your files from the `rbac-policies` ConfigMap:
+
[source,yaml]
----
apiVersion: rhdh.redhat.com/v1alpha3
kind: Backstage
spec:
  application:
    extraFiles:
      mountPath: /opt/app-root/src
      configMaps:
        - name: rbac-policies
----
For detailed information, see {authorization-book-link}managing-authorizations-by-using-external-files[Managing authorizations by using external files].

.Verification

. Log in to your {product-very-short} instance.
. In your {product} navigation menu, you are able to see and access the *Lightspeed* menu item. Clicking this menu takes you to the {ls-short} screen.

image::rhdh-plugins-reference/developer-lightspeed.png[]
