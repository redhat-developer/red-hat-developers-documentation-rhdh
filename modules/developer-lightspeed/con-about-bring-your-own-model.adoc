:_mod-docs-content-type: CONCEPT
[id="con-about-bring-your-own-model_{context}"]
= About Bring Your Own Model

{ls-short} does not provide its own inference services, but uses a _Bring Your Own Model_ approach. This means that you can configure the {rcs-name} to talk to the inference server or service of your choice. This also means that you are responsible for ensuring that the configured service meets your particular company policies and legal requirements, including any applicable terms with the third-party model provider.
//Add the cross reference to "Bring your own model"
The only technical requirements for inference services are:

* The service must conform to the Open AI API specification.
* The service must be configured correctly following the installation and configuration instructions.
// Add the cross-reference to "Installation and configuraiton" after the docs are published
There are many commercial and open source inference services that support the OpenAI API specification for chat completions. The cost, performance, and security of these services can differ and it is up to you to choose, through evaluation and testing, the inference service that best meets your company's needs.
