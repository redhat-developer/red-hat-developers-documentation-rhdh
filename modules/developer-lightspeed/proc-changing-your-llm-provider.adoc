:_mod-docs-content-type: PROCEDURE

[id="proc-changing-your-llm-provider_{context}"]
= Changing your LLM provider in {ls-short}

{ls-short} operates on a {developer-lightspeed-link}#con-about-bring-your-own-model_appendix-about-user-data-security[_Bring Your Own Model_] approach, meaning you must provide and configure access to your preferred large language model (LLM) provider for the service to function. Llama Stack acts as an intermediary layer that handles the configuration and setup of these LLM providers.

.Procedure

* You can define additional LLM providers by updating your Llama Stack app config (`llama-stack`) file. In the `inference` section within your `llama-stack.yaml` file, add your new provider configuration as shown in the following example:
+
[source,yaml]
----
  #START - Adding your LLM provider
  inference:
    - provider_id: vllm
      provider_type: remote::vllm
      config:
        url: ${env.VLLM_URL}
        api_token: ${env.VLLM_API_KEY}
        max_tokens: ${env.VLLM_MAX_TOKENS:=4096}
        tls_verify: ${env.VLLM_TLS_VERIFY:=true}
    - provider_id: sentence-transformers
      provider_type: inline::sentence-transformers
      config: {}
#END - Adding your LLM provider
----