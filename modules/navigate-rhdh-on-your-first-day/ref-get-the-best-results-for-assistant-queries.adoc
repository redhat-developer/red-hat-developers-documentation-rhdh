:_mod-docs-content-type: REFERENCE

[id="ref-get-the-best-results-for-assistant-queries_{context}"]
= Get the best results for assistant queries

To resolve technical blockers and accelerate development tasks, you must structure your queries to provide specific context to the AI assistant. Using precise prompts ensures that {ls-short} generates relevant code snippets, architectural advice, or platform-specific instructions.

Use the following strategies to improve the accuracy of the assistant's output during your development workflow:

Specify technologies::
Instead of asking "How do I use templates?", ask "How do I create a Software Template that scaffolds a Node.js service with a CI/CD pipeline".

Provide context::
Include details about your environment, such as "I am deploying to OpenShift; how do I configure my catalog-info.yaml to show pod health?".

Leverage conversation context::
Ask follow-up questions to refine a previous answer. For example, if the assistant provides a code snippet, you can ask "Now rewrite that using TypeScript interfaces."

Validate with citations::
Examine the provided documentation links and citations in the response to verify that the generated advice aligns with your organization's official standards.

Improve assistant accuracy::
Rate the utility of responses by selecting the **Thumbs up** or **Thumbs down** icons. This feedback helps tune the model for your organization's specific requirements.

[IMPORTANT]
====
To maintain security standards, do not include sensitive personal information, plain-text credentials, or confidential business data in your queries.
====