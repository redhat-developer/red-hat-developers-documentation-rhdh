:_mod-docs-content-type: CONCEPT

[id="con-ensuring-high-availability-with-database-and-cache-layer_{context}"]
= Ensuring high availability with database and cache layers

To achieve high availability (HA) in {product}, you must implement redundancy and failover for the backend service and its external data dependencies. This configuration ensures that {product-very-short} remains operational during component failures by utilizing horizontal scaling, database replication, and a shared logical cache.

.Backend scalability

{product-very-short} stateless backend design enables horizontal scaling. Because persistent data is stored in PostgreSQL and sessions are externalized to the database, any backend instance can serve any request. An optional Redis cache can improve performance by sharing cached data across instances. To maintain backend availability, observe the following architectural requirements:

Deploy multiple backend instances:: Run a minimum of two to three backend instances for basic HA.
Configure a load balancer:: Use platform-provided load balancing (for example, OpenShift Routes, Kubernetes Ingress, or cloud provider load balancers).
Enable health checks:: Configure the load balancer to probe backend health and remove failed instances from rotation.
Disable session affinity (sticky sessions):: Any instance can serve any request due to database-backed sessions.

.Database high availability
PostgreSQL is required for {product-very-short} operations. A database outage renders the deployment non-functional until the database is restored. For production deployments, you must configure PostgreSQL with high availability (primary-replica replication) to minimize downtime.

[IMPORTANT]
====
When you use catalog providers exclusively, the database acts as an indexed cache of data from external sources like Git repositories. In this configuration, the database does not require disaster recovery backups because the catalog data can be repopulated from the external source of truth such as Git repositories, CI/CD platforms, and other integrations.
====

.Cache high availability (optional)

Configuring Redis as a shared logical cache improves performance in production deployments by sharing cached data across multiple backend instances. A shared cache ensures that all instances have access to the same processed data, such as rendered TechDocs. If the logical cache fails, the platform remains functional, but you might experience the following symptoms:

* Slower response times due to cache misses.
* Increased database load as data must be fetched from PostgreSQL.
* No impact on authentication or core functionality.

For production environments requiring maximum performance stability, configure Redis with high availability using Redis Sentinel for small deployments or Redis Cluster for larger deployments with multiple primary nodes.