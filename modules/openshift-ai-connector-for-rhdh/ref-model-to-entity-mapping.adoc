:_mod-docs-content-type: REFERENCE

[id="ref-model-to-entity-mapping_{context}"]
= Model-to-Entity mapping

Model-to-Entity mapping integrates with {openshift-ai-connector-name-short}, the model catalog, and KServe-based Model Deployments (InferenceServices). This integration automatically converts your AI/ML artifacts into familiar {backstage} entities, simplifying management and providing a unified view of your available AI models to your developer teams.

This offering interfaces with the {openshift-ai-connector-name-short}, model catalog, and KServe-based Model Deployments (InferenceServices) to create familiar {backstage} entities.

|===
|{rhoai-short} Artifact |{product-very-short}/{backstage} Entity Kind |{product-very-short}/{backstage} Entity Type |Purpose

|Model Server (InferenceService)
|Component
|`model-server`
|Represents a running, accessible AI model endpoint. See {rhoai-docs-link}/configuring_your_model-serving_platform/index[Configuring your model-serving platform].

|AI Model (Model Registry Version)
|Resource
|`ai-model`
|Represents the specific AI model artifact, for example, `Llama-3-8B`.

|Model Server API Details
|API
|`openapi` (Default)
|Provides the OpenAPI/Swagger specification for the REST endpoint of the model. See https://access.redhat.com/articles/7047935[Red Hat OpenShifT AI: API Tiers]

|Model Cards
|TechDocs
|N/A
|Model cards from the {rhoai-short} model catalog are associated with the Component and Resource entities. See {rhoai-docs-link}/working_with_the_model_catalog/registering-a-model-from-the-model-catalog_working-model-catalog#registering-a-model-from-the-model-catalog_working-model-catalog[Registering a model from the model catalog].
|===

Once the {openshift-ai-connector-name-short} is installed and connected with {rhoai-short}, the transfer of information commences automatically.