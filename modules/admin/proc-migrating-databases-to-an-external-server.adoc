[id="proc-migrating-databases-to-an-external-server_{context}"]
= Migrating local databases to an external database server using the Operator

By default, {product} hosts the data for each plugin in a PostgreSQL database. When you fetch the list of databases, you might see multiple databases based on the number of plugins configured in {product-short}. You can migrate the data from an {product-very-short} instance hosted on a local PostgreSQL server to an external PostgreSQL service, such as AWS RDS, Azure database, or Crunchy database. To migrate the data from each {product-very-short} instance, you can use PostgreSQL utilities, such as link:https://www.postgresql.org/docs/current/app-pgdump.html[`pg_dump`] with link:https://www.postgresql.org/docs/current/app-psql.html[`psql`] or link:https://www.pgadmin.org/[`pgAdmin`]. 

[NOTE]
====
The following procedure uses a link:https://github.com/janus-idp/operator/blob/1.2.x/hack/db_copy.sh[database copy script] to do a quick migration. 
====

.Prerequisites

* You have installed the link:https://www.postgresql.org/docs/current/app-pgdump.html[`pg_dump`] and link:https://www.postgresql.org/docs/current/app-psql.html[`psql`] utilities on your local machine.
* For data export, you have the PGSQL user privileges to make a full dump of local databases.
* For data import, you have the PGSQL admin privileges to create an external database and populate it with database dumps.

.Procedure

. Configure port forwarding for the local PostgreSQL database pod by running the following command on a terminal: 
+
[source,terminal]
----
oc port-forward -n <your-namespace> <pgsql-pod-name> <forward-to-port>:<forward-from-port>
----
Where:
* The `<pgsql-pod-name>` variable denotes the name of a PostgreSQL pod with the format `backstage-psql-<deployment-name>-<_index>`.
* The `<forward-to-port>` variable denotes the port of your choice to forward PostgreSQL data to.
* The `<forward-from-port>` variable denotes the local PostgreSQL instance port, such as `5432`.
+
.Example: Configuring port forwarding
[source,terminal]
----
oc port-forward -n developer-hub backstage-psql-developer-hub-0 15432:5432
----

. Make a copy of the following `db_copy.sh` script and edit the details based on your configuration:
+
[source,script]
----
#!/bin/bash

to_host=<db-service-host> <1>
to_port=5432 <2>
to_user=postgres <3>

from_host=127.0.0.1 <4>
from_port=15432 <5>
from_user=postgres <6>

allDB=("backstage_plugin_app" "backstage_plugin_auth" "backstage_plugin_catalog" "backstage_plugin_permission" "backstage_plugin_scaffolder" "backstage_plugin_search") <7>

for db in ${!allDB[@]};
do
  db=${allDB[$db]}
  echo Copying database: $db
  PGPASSWORD=$TO_PSW psql -h $to_host -p $to_port -U $to_user -c "create database $db;"
  pg_dump -h $from_host -p $from_port -U $from_user -d $db | PGPASSWORD=$TO_PSW psql -h $to_host -p $to_port -U $to_user -d $db
done
----
<1> The destination host name, for example, `<db-instance-name>.rds.amazonaws.com`.
<2> The destination port, such as `5432`.
<3> The destination server username, for example, `postgres`.
<4> The source host name, such as `127.0.0.1`.
<5> The source port number, such as the `<forward-to-port>` variable. 
<6> The source server username, for example, `postgres`.
<7> The name of databases to import in double quotes separated by spaces, for example, `("backstage_plugin_app" "backstage_plugin_auth" "backstage_plugin_catalog" "backstage_plugin_permission" "backstage_plugin_scaffolder" "backstage_plugin_search")`.

. Create a destination database for copying the data:
+
[source,terminal]
----
/bin/bash TO_PSW=<destination-db-password> /path/to/db_copy.sh <1>
----
<1> The `<destination-db-password>` variable denotes the password to connect to the destination database.
+
[NOTE]
====
You can stop port forwarding when the copying of the data is complete. For more information about handling large databases and using the compression tools, see the link:https://www.postgresql.org/docs/current/backup-dump.html#BACKUP-DUMP-LARGE[Handling Large Databases] section on the PostgreSQL website.
====

. Reconfigure your `Backstage` custom resource (CR). For more information, see link:{LinkAdminGuide}#proc-configuring-postgresql-instance-using-operator_admin-rhdh[Configuring an external PostgreSQL instance using the Operator]. 
. Check that the following code is present at the end of your `Backstage` CR after reconfiguration:
+
[source,yaml]
----
# ...
spec:
  database:
    enableLocalDb: false 
  application:
  # ... 
    extraFiles:
      secrets:
        - name: <crt-secret> 
          key: postgres-crt.pem # key name as in <crt-secret> Secret
    extraEnvs:
      secrets:
        - name: <cred-secret> 
# ...        
----
+
[NOTE]
====
Reconfiguring the `Backstage` CR deletes the corresponding `StatefulSet` and `Pod` objects, but does not delete the `PersistenceVolumeClaim` object. Use the following command to delete the local `PersistenceVolumeClaim` object:

[source,terminal]
----
oc -n developer-hub delete pvc <local-psql-pvc-name>
----
where, the `<local-psql-pvc-name>` variable is in the `data-<psql-pod-name>` format.
====

. Apply the configuration changes.


.Verification

. Verify that your {product-very-short} instance is running and contains the migrated data by running the following command:
+
[source,terminal]
----
oc get pods -n <your-namespace>
----

. Check the output for the following details:
* The `backstage-developer-hub-xxx` pod is in running state.
* The `backstage-psql-developer-hub-0` pod is not available.
+
You can also verify these details using the *Topology* view in the {ocp-short} web console.
