<?xml version='1.0' encoding='UTF-8'?>
<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" class="chrometwo"><head><title>Interacting with Red Hat Developer Lightspeed for Red Hat Developer Hub</title><link rel="stylesheet" type="text/css" href="Common_Content/css/default.css"/><meta name="generator" content="publican v4.3.2"/><meta name="description" content="Leverage Artificial Intelligence (AI)-driven expertise of the Red Hat Developer Lightspeed for Red Hat Developer Hub (Developer Lightspeed for RHDH) virtual assistant to help you use Red Hat Developer Hub (RHDH)"/><link rel="next" href="#developer-lightspeed" title="1. Interacting with Red Hat Developer Lightspeed for Red Hat Developer Hub"/><meta http-equiv="Content-Type" content="text/html; charset=UTF-8"/><script type="text/javascript" src="Common_Content/scripts/jquery-1.7.1.min.js"> </script><script type="text/javascript" src="Common_Content/scripts/utils.js"> </script><script type="text/javascript" src="Common_Content/scripts/highlight.js/highlight.pack.js"> </script></head><body><div id="chrometwo"><div id="main"><section xml:lang="en-US" class="article" id="idm46463601737024"><div class="titlepage"><div><div class="producttitle"><span class="productname">Red Hat Developer Hub</span> <span class="productnumber">1.9</span></div><div><h1 class="title">Interacting with Red Hat Developer Lightspeed for Red Hat Developer Hub</h1></div><div><h3 class="subtitle"><em>Leverage Artificial Intelligence (AI)-driven expertise of the Red Hat Developer Lightspeed for Red Hat Developer Hub (Developer Lightspeed for RHDH) virtual assistant to help you use Red Hat Developer Hub (RHDH)</em></h3></div><div><div xml:lang="en-US" class="authorgroup"><span class="orgname">Red Hat Customer Content Services</span></div></div><div><a href="#idm46463587173968">Legal Notice</a></div><div><div class="abstract"><p class="title"><strong>Abstract</strong></p><div class="para">
				Leverage Artificial Intelligence (AI)-driven expertise of the Red Hat Developer Lightspeed for Red Hat Developer Hub (Developer Lightspeed for RHDH) virtual assistant to help you use Red Hat Developer Hub (RHDH)
			</div></div></div></div><hr/></div><div class="toc"><ul class="toc"><li><span class="section"><a href="#developer-lightspeed">1. Interacting with Red Hat Developer Lightspeed for Red Hat Developer Hub</a></span><ul><li><span class="section"><a href="#con-about-developer-lightspeed_developer-lightspeed">1.1. About Developer Lightspeed for RHDH</a></span></li><li><span class="section"><a href="#con-supported-architecture_developer-lightspeed">1.2. Supported architecture for Red Hat Developer Lightspeed for Red Hat Developer Hub</a></span></li><li><span class="section"><a href="#con-rag-embeddings_developer-lightspeed">1.3. Retrieval augmented generation (RAG) embeddings</a></span></li><li><span class="section"><a href="#proc-installing-and-configuring-lightspeed_developer-lightspeed">1.4. Installing and configuring Red Hat Developer Lightspeed for Red Hat Developer Hub</a></span></li><li><span class="section"><a href="#customizing-developer-lightspeed">1.5. Customizing Developer Lightspeed for RHDH</a></span></li><li><span class="section"><a href="#get-ai-assisted-help">1.6. Get AI-assisted help for your development tasks</a></span></li><li><span class="section"><a href="#appendix-llm-requirements">1.7. Appendix: LLM requirements</a></span></li><li><span class="section"><a href="#appendix-about-user-data-security">1.8. Appendix About user data security</a></span></li></ul></li></ul></div><section class="section" id="developer-lightspeed"><div class="titlepage"><div><div><h2 class="title">1. Interacting with Red Hat Developer Lightspeed for Red Hat Developer Hub</h2></div></div></div><p>
			Red Hat Developer Lightspeed for Red Hat Developer Hub (Developer Lightspeed for RHDH) is a virtual assistant powered by generative Artificial Intelligence (AI) designed for Red Hat Developer Hub(RHDH). The assistant offers in-depth insights into RHDH, including its wide range of capabilities. You can interact with this assistant to explore and learn more about RHDH in greater detail.
		</p><section class="section" id="con-about-developer-lightspeed_developer-lightspeed"><div class="titlepage"><div><div><h3 class="title">1.1. About Developer Lightspeed for RHDH</h3></div></div></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
					This section describes Developer Preview features in the Red Hat Developer Lightspeed for Red Hat Developer Hub plugin. Developer Preview features are not supported by Red Hat in any way and are not functionally complete or production-ready. Do not use Developer Preview features for production or business-critical workloads. Developer Preview features provide early access to functionality in advance of possible inclusion in a Red Hat product offering. Customers can use these features to test functionality and provide feedback during the development process. Developer Preview features might not have any documentation, are subject to change or removal at any time, and have received limited testing. Red Hat might provide ways to submit feedback on Developer Preview features without an associated SLA.
				</p><p>
					For more information about the support scope of Red Hat Developer Preview features, see <a class="link" href="https://access.redhat.com/support/offerings/devpreview/">Developer Preview Support Scope</a>.
				</p></div></div><p>
				This early access program enables customers to share feedback on the user experience, features, capabilities, and any issues encountered. Your input helps ensure that Developer Lightspeed for RHDH better meets your needs when it is officially released and made generally available.
			</p><p>
				Developer Lightspeed for RHDH provides a natural language interface within the RHDH console, helping you easily find information about the product, understand its features, and get answers to your questions.
			</p><p>
				You can experience Developer Lightspeed for RHDH Developer Preview by installing the Developer Lightspeed for RHDH plugin within an existing RHDH instance. Alternatively, if you prefer to test it locally first, you can try Developer Lightspeed for RHDH using RHDH Local.
			</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
					Developer Lightspeed for RHDH uses a FAB instead of a sidebar navigation item. If your environment uses another global FAB, you must move the existing button or disable it to prevent interface elements from overlapping. In your dynamic plugin configuration file, make the following update:
				</p><pre class="programlisting language-yaml">- package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import
  disabled: true
  pluginConfig:
    dynamicPlugins:
      frontend:
        red-hat-developer-hub.backstage-plugin-bulk-import:
          mountPoints:
            - mountPoint: global.floatingactionbutton/config
              importName: BulkImportPage # Example
              config:
                slot: 'bottom-left'
                icon: BulkImportIcon
                label: 'Bulk import'
                toolTip: 'Register multiple repositories in bulk'
                to: /bulk-import
          translationResources:
          - importName: bulkImportTranslations
            module: Alpha
            ref: bulkImportTranslationRef
          appIcons:
          - name: bulkImportIcon
            importName: BulkImportIcon
          dynamicRoutes:
          - path: /bulk-import
            importName: BulkImportPage
            menuItem:
              icon: bulkImportIcon
              text: Bulk import
              textKey: menuItem.bulkImport</pre></div></div><div class="informalfigure"><div class="mediaobject"/></div><div class="itemizedlist"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://github.com/redhat-developer/rhdh-local/blob/main/README.md">RHDH Local</a>
					</li></ul></div></section><section class="section" id="con-supported-architecture_developer-lightspeed"><div class="titlepage"><div><div><h3 class="title">1.2. Supported architecture for Red Hat Developer Lightspeed for Red Hat Developer Hub</h3></div></div></div><p>
				Developer Lightspeed for RHDH is available as a plugin on all platforms that host RHDH. It requires two sidecar containers: the Lightspeed Core Service (LCS) and the Llama Stack service.
			</p><p>
				The LCS container acts as the intermediary layer, which interfaces with and manages the Llama Stack service.
			</p><div class="informalfigure"><div class="mediaobject"><img src="images/rhdh-plugins-reference/developer-lightspeed-architecture-1-8-0.png" alt="developer lightspeed architecture 1 8 0"/></div></div><div class="itemizedlist"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						<a class="link" href="https://access.redhat.com/support/policy/updates/developerhub">Red Hat Developer Hub Life Cycle and supported platforms</a>
					</li></ul></div><section class="section" id="con-about-lightspeed-stack-and-llama-stack_developer-lightspeed"><div class="titlepage"><div><div><h4 class="title">1.2.1. About Lightspeed Core Service and Llama Stack</h4></div></div></div><p>
					The Lightspeed Core Service and Llama Stack deploy together as sidecar containers to augment RHDH functionality.
				</p><p>
					The Llama Stack delivers the augmented functionality by integrating and managing core components, which include:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							Large language model (LLM) inference providers
						</li><li class="listitem"><p class="simpara">
							Model Context Protocol (MCP) or Retrieval Augmented Generation (RAG) tool runtime providers
						</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
								You must verify that your model supports tool calling before you enable Model Context Protocol (MCP) features. Using an incompatible model results in error messages.
							</p></div></div></li><li class="listitem">
							Safety providers
						</li><li class="listitem">
							Vector database settings
						</li></ul></div><p>
					The Lightspeed Core Service serves as the Llama Stack service intermediary. It manages the operational configuration and key data, specifically:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							User feedback collection
						</li><li class="listitem">
							MCP server configuration
						</li><li class="listitem">
							Conversation history
						</li></ul></div><p>
					Llama Stack provides the inference functionality that LCS uses to process requests. For more information, see <a class="link" href="https://llamastack.github.io/docs#what-is-llama-stack">What is Llama Stack</a>.
				</p><p>
					The Red Hat Developer Lightspeed for Red Hat Developer Hub plugin in RHDH sends prompts and receives LLM responses through the LCS sidecar. LCS then uses the Llama Stack sidecar service to perform inference and MCP or RAG tool calling.
				</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						Red Hat Developer Lightspeed for Red Hat Developer Hub is a Developer Preview release. You must manually deploy the Lightspeed Core Service and Llama Stack sidecar containers, and install the Red Hat Developer Lightspeed for Red Hat Developer Hub plugin on your RHDH instance.
					</p></div></div></section></section><section class="section" id="con-rag-embeddings_developer-lightspeed"><div class="titlepage"><div><div><h3 class="title">1.3. Retrieval augmented generation (RAG) embeddings</h3></div></div></div><p>
				The Red Hat Developer Hub documentation serves as the Retrieval-Augmented Generation (RAG) data source.
			</p><p>
				RAG initialization occurs through an initialization container, which copies the RAG data to a shared volume. The Llama Stack sidecar then mounts this shared volume to access the RAG data. The Llama Stack service uses the resulting RAG embeddings in the vector database as a reference. This allows the service to provide citations to production documentation during the inference process.
			</p></section><section class="section" id="proc-installing-and-configuring-lightspeed_developer-lightspeed"><div class="titlepage"><div><div><h3 class="title">1.4. Installing and configuring Red Hat Developer Lightspeed for Red Hat Developer Hub</h3></div></div></div><p>
				Developer Lightspeed for RHDH includes several components that work together to provide virtual assistant (chat) functionality:
			</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Llama stack server (container sidecar)</span></dt><dd>
							Based on open source <a class="link" href="https://github.com/llamastack/llama-stack">Llama Stack</a>, this service is the gateway to your LLM inferencing provider for chat services. Its modular architecture supports integrating other services, such as Model Context Protocol (MCP). To enable chat functionality, you must integrate your LLM provider with the Llama Stack server using <span class="emphasis"><em>Bring Your Own Model</em></span> or BYOM.
						</dd><dt><span class="term">Lightspeed Core Service (LCS) (container sidecar)</span></dt><dd>
							Based on the open source <a class="link" href="https://github.com/lightspeed-core">Lightspeed Core</a>, this service extends the Llama Stack server by maintaining chat history and gathering user feedback.
						</dd><dt><span class="term">Red Hat Developer Lightspeed for Red Hat Developer Hub (dynamic plugins)</span></dt><dd>
							These plugins enable the Developer Lightspeed for RHDH user interface within your RHDH instance.
						</dd></dl></div><p>
				To provide Developer Lightspeed for RHDH to your users, you must configure these components to communicate with each other.
			</p><div class="admonition note"><div class="admonition_header">Note</div><div><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							If you are upgrading from the previous Developer Lightspeed for RHDH Developer Preview with Road-Core Service, you must remove all existing Developer Lightspeed for RHDH configurations before reinstalling.
						</li><li class="listitem">
							To prevent or resolve upgrade inconsistencies, drop and recreate the dynamic plugins volume.
						</li></ul></div><p>
					This reinstallation is required due to the following fundamental architectural changes:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							The previous release used Road-Core Service as a sidecar container for interfacing with LLM providers.
						</li><li class="listitem">
							The updated architecture replaces {rcs-short} with the new Lightspeed Core Service and Llama Stack server, which requires new configurations for the plugins, volumes, containers, and secrets.
						</li></ul></div></div></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
						You are logged in to your OpenShift Container Platform account.
					</li><li class="listitem">
						You have an RHDH instance installed using either the Operator or the Helm chart.
					</li><li class="listitem">
						You have created a <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_developer_hub/1.9/html-single/installing_and_viewing_plugins_in_red_hat_developer_hub/index#rhdh-installing-rhdh-plugins_title-plugins-rhdh-about">custom dynamic plugins ConfigMap</a>.
					</li><li class="listitem">
						You have administrative access to the RHDH configuration files.
					</li></ul></div><div class="formalpara"><p class="title"><strong>Procedure</strong></p><p>
					You must manually install and configure the Developer Lightspeed for RHDH plugin, the Lightspeed Core Service (LCS) sidecar container, and the Llama Stack sidecar container.
				</p></div><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
						Create the Lightspeed Core Service (LCS) ConfigMap to store the service configuration:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
								In the OpenShift Container Platform web console, navigate to your RHDH instance and select the <span class="strong strong"><strong>ConfigMaps</strong></span> tab.
							</li><li class="listitem">
								Click <span class="strong strong"><strong>Create ConfigMaps</strong></span>.
							</li><li class="listitem"><p class="simpara">
								Select <span class="strong strong"><strong>YAML view</strong></span> and edit the file using the following structure. This example demonstrates the configuration for the LCS ConfigMap, typically named <code class="literal">lightspeed-stack</code>, which connects to the Llama Stack service locally on port <code class="literal">8321</code>:
							</p><pre class="programlisting language-yaml">kind: ConfigMap
apiVersion: v1
metadata:
  name: lightspeed-stack
data:
  lightspeed-stack.yaml: |
    name: Lightspeed Core Service (LCS)
    service:
      host: 0.0.0.0
    # Use ${LIGHTSPEED_SERVICE_PORT} if you are not running the Service on port `8080`
    # port: ${LIGHTSPEED_SERVICE_PORT}
      auth_enabled: false
      workers: 1
      color_log: true
      access_log: true
    llama_stack:
      use_as_library_client: false
      url: http://localhost:8321
    user_data_collection:
      feedback_enabled: true
      feedback_storage: "/tmp/data/feedback"
      transcripts_enabled: true
      transcripts_storage: "/tmp/data/transcripts"
    authentication:
      module: "noop"
    conversation_cache:
      type: "sqlite"
      sqlite:
        db_path: "/tmp/data/conversations/lcs_cache.db"</pre><div class="admonition important"><div class="admonition_header">Important</div><div><p>
									LCS uses Llama Stack expansion syntax for environment variables. To make sure the service correctly parses variables in the <code class="literal">lightspeed-stack.yaml</code> file, you must use the <code class="literal">${env.VAR}</code> format. Variable names are case-sensitive and must be uppercase. The syntax <code class="literal">${env.var}</code> is not supported. For example:
								</p><pre class="programlisting language-yaml">model_config:
  api_key: ${env.VAR}</pre></div></div></li><li class="listitem">
								Click <span class="strong strong"><strong>Create</strong></span>.
							</li></ol></div></li><li class="listitem"><p class="simpara">
						Create the Developer Lightspeed for RHDH ConfigMap (<code class="literal">lightspeed-app-config</code>) for plugin configurations:
					</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
								In the OpenShift Container Platform web console, navigate to your RHDH instance and select the <span class="strong strong"><strong>ConfigMaps</strong></span> tab.
							</li><li class="listitem">
								Click <span class="strong strong"><strong>Create ConfigMap</strong></span>.
							</li><li class="listitem"><p class="simpara">
								Select the <span class="strong strong"><strong>YAML view</strong></span> option and add the following configuration:
							</p><pre class="programlisting language-yaml">kind: ConfigMap
apiVersion: v1
metadata:
  name: lightspeed-app-config
  namespace: &lt;__namespace__&gt; # Enter your RHDH instance namespace
data:
  app-config.yaml: |-
    backend:
      csp:
        upgrade-insecure-requests: false
      img-src:
        - "'self'"
        - "data:"
        - https://img.freepik.com
        - https://cdn.dribbble.com
        - https://avatars.githubusercontent.com # This is to load GitHub avatars in the UI
      script-src:
        - "'self'"
        - "'unsafe-eval'"
        - https://cdn.jsdelivr.net

    lightspeed:
      # OPTIONAL: Custom users prompts displayed to users
      # If not provided, the plugin uses built-in default prompts
      prompts:
        - title: Getting Started with Red Hat Developer Hub
          message: Can you guide me through the first steps to start using {product-short} as a developer, like exploring the Software Catalog and adding my service?

      # OPTIONAL: Port for lightspeed service (default: 8080)
      # servicePort: ${LIGHTSPEED_SERVICE_PORT}

      # OPTIONAL: Override default RHDH system prompt
      # systemPrompt: "You are a helpful assistant focused on Red Hat Developer Hub development."</pre></li><li class="listitem">
								Click <span class="strong strong"><strong>Create</strong></span>.
							</li></ol></div></li><li class="listitem"><p class="simpara">
						Create Llama Stack Secret file (<code class="literal">llama-stack-secrets</code>) for LLM provider credentials:
					</p><div class="admonition important"><div class="admonition_header">Important</div><div><p>
							Red Hat Developer Hub 1.9 configures the Llama Stack image to use the vLLM provider exclusively. The vLLM provider supports the OpenAI API schema but does not support connecting directly to the official OpenAI service (<code class="literal">api.openai.com</code>). Do not use the official OpenAI API URL or token with vLLM in this release. Attempting this might result in errors or improper responses. Native OpenAI provider support is planned for future releases.
						</p></div></div><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem">
								In the OpenShift Container Platform web console, navigate to <span class="strong strong"><strong>Secrets</strong></span>.
							</li><li class="listitem">
								Click <span class="strong strong"><strong>Create</strong></span> → <span class="strong strong"><strong>Key/value secret</strong></span>.
							</li><li class="listitem"><p class="simpara">
								Select the <span class="strong strong"><strong>YAML view</strong></span> option and add the following structure:
							</p><pre class="programlisting language-yaml">apiVersion: v1
kind: Secret
metadata:
  name: llama-stack-secrets
type: Opaque
stringData:
  ENABLE_VLLM: "true"
  ENABLE_VERTEX_AI: ""
  ENABLE_OPENAI: ""
  ENABLE_OLLAMA: ""
  VLLM_URL: "_&lt;api_endpoint&gt;_"
  VLLM_API_KEY: "_&lt;api_key&gt;_"
  VLLM_MAX_TOKENS: ""
  VLLM_TLS_VERIFY: ""
  OPENAI_API_KEY: ""
  VERTEX_AI_PROJECT: ""
  VERTEX_AI_LOCATION: ""
  GOOGLE_APPLICATION_CREDENTIALS: ""
  OLLAMA_URL: ""
  SAFETY_MODEL: "llama-guard3:8b"
  SAFETY_URL: "http://localhost:#####/v1"
  SAFETY_API_KEY: ""</pre><p class="simpara">
								where:
							</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">ENABLE_VLLM</code></span></dt><dd>
											Enables the vLLM provider. Set to true to activate.
										</dd><dt><span class="term"><code class="literal">ENABLE_OPENAI</code></span></dt><dd>
											Enables the OpenAI provider. Set to true to activate.
										</dd><dt><span class="term"><code class="literal">ENABLE_VERTEX_AI</code></span></dt><dd>
											Enables the Vertex AI provider. Set to true to activate.
										</dd><dt><span class="term"><code class="literal">ENABLE_OLLAMA</code></span></dt><dd>
											Enables the Ollama provider. Set to true to activate.
										</dd></dl></div></li></ol></div></li></ol></div><div class="informalexample"><p>
				To disable a provider, leave the value blank. (for example: ENABLE_VLLM="")
			</p></div><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">VLLM_URL</code></span></dt><dd>
							The API endpoint URL for the LLM provider. The provider must comply with the OpenAI API specification. Examples include OpenAI, Red Hat OpenShift AI, and vLLM.
						</dd><dt><span class="term"><code class="literal">VLLM_API_KEY</code></span></dt><dd>
							Required for remote services: Set this to the API key or token required for authentication with your remote LLM provider, if it is compatible with the OpenAI API specification.
						</dd><dt><span class="term"><code class="literal">VLLM_MAX_TOKENS</code></span></dt><dd>
							Optional. The maximum number of tokens the model generates.
						</dd><dt><span class="term"><code class="literal">VLLM_TLS_VERIFY</code></span></dt><dd>
							Optional. Specifies whether the system verifies the TLS certificate for the vLLM endpoint.
						</dd><dt><span class="term"><code class="literal">OPENAI_API_KEY</code></span></dt><dd>
							The API key required to access OpenAI models through the OpenAI API.
						</dd><dt><span class="term"><code class="literal">VERTEX_AI_PROJECT</code></span></dt><dd>
							The Google Cloud project ID required to access Gemini through Vertex AI.
						</dd><dt><span class="term"><code class="literal">VERTEX_AI_LOCATION</code></span></dt><dd>
							The Google Cloud region required to access Gemini through Vertex AI.
						</dd><dt><span class="term"><code class="literal">GOOGLE_APPLICATION_CREDENTIALS</code></span></dt><dd>
							The credentials required to authenticate with Google Cloud to access Vertex AI.
						</dd><dt><span class="term"><code class="literal">OLLAMA_URL</code></span></dt><dd>
							The URL for the Ollama service.
						</dd><dt><span class="term"><code class="literal">SAFETY_MODEL</code></span></dt><dd>
							The identifier for the safety model. The recommended value is llama-guard3:8b.
						</dd><dt><span class="term"><code class="literal">SAFETY_URL</code></span></dt><dd>
							The URL hosting the safety model. You must append <code class="literal">/v1</code> to the host address (for example: <code class="literal">localhost:<span class="marked marked">#</span>/v1</code>).
						</dd><dt><span class="term"><code class="literal">SAFETY_API_KEY</code></span></dt><dd><p class="simpara">
							The API key required to authenticate with the safety model, if applicable.
						</p><div class="orderedlist"><ol class="orderedlist" type="a"><li class="listitem"><p class="simpara">
									Click <span class="strong strong"><strong>Create</strong></span>.
								</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
											Update the dynamic plugins ConfigMap: Add the Developer Lightspeed for RHDH plugin image to your existing dynamic plugins ConfigMap (<code class="literal">dynamic-plugins-rhdh</code>).
										</p><pre class="programlisting language-yaml">includes:
- dynamic-plugins.default.yaml
plugins:
- disabled: false
  package: oci://ghcr.io/redhat-developer/rhdh-plugin-export-overlays/red-hat-developer-hub-backstage-plugin-lightspeed:bs_1.45.3__1.2.3
  pluginConfig:
    dynamicPlugins:
      frontend:
        red-hat-developer-hub.backstage-plugin-lightspeed:
              translationResources:
                - importName: lightspeedTranslations
                  module: Alpha
                  ref: lightspeedTranslationRef
              dynamicRoutes:
                - path: /lightspeed
                  importName: LightspeedPage
              mountPoints:
                - mountPoint: application/listener
                  importName: LightspeedFAB
                - mountPoint: application/provider
                  importName: LightspeedDrawerProvider
                - mountPoint: application/internal/drawer-state
                  importName: LightspeedDrawerStateExposer
                  config:
                    id: lightspeed
                - mountPoint: application/internal/drawer-content
                  importName: LightspeedChatContainer
                  config:
                    id: lightspeed
                    priority: 100
- disabled: false
  package: oci://ghcr.io/redhat-developer/rhdh-plugin-export-overlays/red-hat-developer-hub-backstage-plugin-lightspeed-backend:bs_1.45.3__1.2.3</pre></li><li class="listitem"><p class="simpara">
											Required only if your environment uses another global floating action button (FAB): You must move the existing FAB or disable it to prevent interface elements from overlapping by updating your dynamic plugin configuration file with the following changes:
										</p><pre class="programlisting language-yaml">- package: ./dynamic-plugins/dist/red-hat-developer-hub-backstage-plugin-bulk-import
  disabled: true
  pluginConfig:
    dynamicPlugins:
      frontend:
        red-hat-developer-hub.backstage-plugin-bulk-import:
          mountPoints:
          # START: If the user has an existing BulkImportPage FAB, move the FAB to the left
            - mountPoint: global.floatingactionbutton/config
              importName: BulkImportPage
              config:
                slot: 'bottom-left'
          # END
                icon: BulkImportIcon
                label: 'Bulk import'
                toolTip: 'Register multiple repositories in bulk'
                to: /bulk-import
          translationResources:
          - importName: bulkImportTranslations
            module: Alpha
            ref: bulkImportTranslationRef
          appIcons:
          - name: bulkImportIcon
            importName: BulkImportIcon
          dynamicRoutes:
          - path: /bulk-import
            importName: BulkImportPage
            menuItem:
              icon: bulkImportIcon
              text: Bulk import
              textKey: menuItem.bulkImport</pre></li><li class="listitem"><p class="simpara">
											Update your deployment configuration: Update the deployment configuration based on how your RHDH instance was installed. You must add two sidecar containers: <code class="literal">llama-stack</code> and <code class="literal">lightspeed-core</code>.
										</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
													For an Operator-installed RHDH instance (Update Backstage custom resource (CR)):
												</p><div class="orderedlist"><ol class="orderedlist" type="i"><li class="listitem"><p class="simpara">
															In the <code class="literal">spec.application.appConfig.configMaps</code> section of your Backstage CR, add the Developer Lightspeed for RHDH custom app configuration:
														</p><pre class="programlisting language-yaml">appConfig:
  configMaps:
    - name: lightspeed-app-config</pre></li><li class="listitem"><p class="simpara">
															Update the <code class="literal">spec.deployment.patch.spec.template.spec.volumes</code> specification to include volumes for LCS configuration (<code class="literal">lightspeed-stack</code>), shared storage for feedback (<code class="literal">shared-storage</code>), and RAG data (<code class="literal">rag-data-volume</code>):
														</p><pre class="programlisting language-yaml">volumes:
  - configMap:
      name: lightspeed-stack
    name: lightspeed-stack
  - emptyDir: {}
    name: shared-storage
  - emptyDir: {}
    name: rag-data-volume</pre></li><li class="listitem">
															Add the <code class="literal">initContainers</code> section to initialize RAG data:
														</li></ol></div></li></ul></div></li></ol></div></li></ol></div></dd></dl></div><pre class="programlisting language-yaml">+
----
initContainers:
  - name: init-rag-data
    image: 'quay.io/redhat-ai-dev/rag-content:release-1.9-lcs'
    command:
      - "sh"
      - "-c"
      - "echo 'Copying RAG data...'; cp -r /rag/vector_db/rhdh_product_docs /rag-content/ &amp;&amp; cp -r /rag/embeddings_model /rag-content/ &amp;&amp; echo 'Copy complete.'"
    volumeMounts:
      - mountPath: /rag-content
        name: rag-data-volume
----
... Add the Llama Stack and the {lcs-short} containers to the `spec.deployment.patch.spec.template.spec.containers` section:</pre><p>
				+
			</p><pre class="programlisting language-yaml">containers:
  # ... Your existing RHDH container definition ...
  - envFrom:
      - secretRef:
          name: llama-stack-secrets
    image: 'quay.io/redhat-ai-dev/llama-stack:0.1.4' # Llama Stack image
    name: llama-stack
    volumeMounts:
      - mountPath: /app-root/.llama
        name: shared-storage
      - mountPath: /rag-content
        name: rag-data-volume
  - image: 'quay.io/lightspeed-core/lightspeed-stack:0.4.0' # Lightspeed Core Service image
    name: lightspeed-core
    volumeMounts:
      - mountPath: /app-root/lightspeed-stack.yaml
        name: lightspeed-stack
        subPath: lightspeed-stack.yaml
      - mountPath: /tmp/data/feedback
        name: shared-storage
      - mountPath: /tmp/data/transcripts
        name: shared-storage
      - mountPath: /tmp/data/conversations
        name: shared-storage</pre><div class="orderedlist"><ol class="orderedlist" type="i"><li class="listitem"><p class="simpara">
						Click <span class="strong strong"><strong>Save</strong></span>. The Pods are automatically restarted.
					</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								For a Helm-installed RHDH instance (Update the Helm chart):
							</li></ul></div></li><li class="listitem"><p class="simpara">
						Add your dynamic plugins configuration in the <code class="literal">global.dynamic</code> property.
					</p><pre class="programlisting language-yaml">global:
  dynamic:
    plugins:
      - package: oci://ghcr.io/redhat-developer/rhdh-plugin-export-overlays/red-hat-developer-hub-backstage-plugin-lightspeed:bs_1.45.3__1.2.3
        pluginConfig:
          dynamicPlugins:
            frontend:
              red-hat-developer-hub.backstage-plugin-lightspeed:
                translationResources:
                  - importName: lightspeedTranslations
                    module: Alpha
                    ref: lightspeedTranslationRef
                dynamicRoutes:
                  - path: /lightspeed
                    importName: LightspeedPage
                mountPoints:
                  - mountPoint: application/listener
                    importName: LightspeedFAB
                  - mountPoint: application/provider
                    importName: LightspeedDrawerProvider
                  - mountPoint: application/internal/drawer-state
                    importName: LightspeedDrawerStateExposer
                    config:
                      id: lightspeed
                  - mountPoint: application/internal/drawer-content
                    importName: LightspeedChatContainer
                    config:
                      id: lightspeed
                      priority: 100
      - package: oci://ghcr.io/redhat-developer/rhdh-plugin-export-overlays/red-hat-developer-hub-backstage-plugin-lightspeed-backend:bs_1.45.3__1.2.3</pre></li><li class="listitem"><p class="simpara">
						Add your Developer Lightspeed for RHDH custom app config file to <code class="literal">extraAppConfig</code>:
					</p><pre class="programlisting language-yaml">    extraAppConfig:
      - configMapRef: lightspeed-app-config
        filename: app-config.yaml</pre></li><li class="listitem"><p class="simpara">
						Add the Llama Stack Secret file to <code class="literal">extraEnvVarsSecrets</code>:
					</p><pre class="programlisting language-yaml">    extraEnvVarsSecrets:
      - llama-stack-secrets</pre></li><li class="listitem"><p class="simpara">
						Update the <code class="literal">extraVolumes</code> section to include the LCS ConfigMap (<code class="literal">lightspeed-stack</code>), shared storage, and RAG data volume:
					</p><pre class="programlisting language-yaml">    extraVolumes:
      - configMap:
          name: lightspeed-stack
        name: lightspeed-stack
      - emptyDir: {}
        name: shared-storage
      - emptyDir: {}
        name: rag-data-volume</pre></li><li class="listitem"><p class="simpara">
						Update the <code class="literal">initContainers</code> section (if supported by your Helm chart structure) to initialize RAG data.
					</p><pre class="programlisting language-yaml">  initContainers:
      - name: init-rag-data
        image: 'quay.io/redhat-ai-dev/rag-content:release-1.9-lcs'
        command:
          - "sh"
          - "-c"
          - "echo 'Copying RAG data...'; cp -r /rag/vector_db/rhdh_product_docs /data/ &amp;&amp; cp -r /rag/embeddings_model /data/ &amp;&amp; echo 'Copy complete.'"
        volumeMounts:
          - mountPath: /data
            name: rag-data-volume</pre></li><li class="listitem"><p class="simpara">
						Add the Llama Stack and LCS container definitions to <code class="literal">extraContainers</code>.
					</p><div class="admonition note"><div class="admonition_header">Note</div><div><p>
							If you have Road-Core Service installed from the previous Red Hat Developer Lightspeed for Red Hat Developer Hub configuration, you must replace the older single container configuration found in source with the two sidecars.
						</p></div></div><pre class="programlisting language-yaml">    extraContainers:
      # Llama Stack Container
      - envFrom:
          - secretRef:
              name: llama-stack-secrets
        image: 'quay.io/redhat-ai-dev/llama-stack:0.1.4'
        name: llama-stack
        volumeMounts:
          - mountPath: /app-root/.llama
            name: shared-storage
          - mountPath: /app-root/embeddings_model
            name: rag-data-volume
            subPath: embeddings_model
          - mountPath: /app-root/vector_db/rhdh_product_docs
            name: rag-data-volume
            subPath: rhdh_product_docs
      # Lightspeed Core Service Container
      - image: 'quay.io/lightspeed-core/lightspeed-stack:0.4.0'
        name: lightspeed-core
        volumeMounts:
          - mountPath: /app-root/lightspeed-stack.yaml
            name: lightspeed-stack
            subPath: lightspeed-stack.yaml
          - mountPath: /tmp/data/feedback
            name: shared-storage
          - mountPath: /tmp/data/transcripts
            name: shared-storage
          - mountPath: /tmp/data/conversations
            name: shared-storage</pre></li><li class="listitem"><p class="simpara">
						Click <span class="strong strong"><strong>Save</strong></span> and then Helm upgrade.
					</p><div class="orderedlist"><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
								Optional: Manage authorization (RBAC): If you have users who are not administrators, you must <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_developer_hub/1.9/html-single/authorization_in_red_hat_developer_hub/index#enabling-and-giving-access-to-rbac">define permissions and roles</a> for them to use Developer Lightspeed for RHDH. The Lightspeed Backend plugin uses Backstage RBAC for authorization.
							</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
										For an Operator-installed RHDH instance:
									</li></ul></div></li></ol></div></li><li class="listitem"><p class="simpara">
						Configure the required RBAC permission by defining an <code class="literal">rbac-policies.csv</code> file, including <code class="literal">lightspeed.chat.read</code>, <code class="literal">lightspeed.chat.create</code>, and <code class="literal">lightspeed.chat.delete</code> permissions:
					</p><pre class="programlisting language-csv">p, role:default/_&lt;your_team&gt;_, lightspeed.chat.read, read, allow
p, role:default/_&lt;your_team&gt;_, lightspeed.chat.create, create, allow
p, role:default/_&lt;your_team&gt;_, lightspeed.chat.delete, delete, allow
g, user:default/_&lt;your_user&gt;_, role:default/_&lt;your_team&gt;_</pre></li><li class="listitem"><p class="simpara">
						Upload your <code class="literal">rbac-policies.csv</code> file to an <code class="literal">rbac-policies</code> ConfigMap in your OpenShift Container Platform project containing RHDH and update your Backstage CR:
					</p><pre class="programlisting language-yaml">apiVersion: rhdh.redhat.com/v1alpha5
kind: Backstage
spec:
  application:
    extraFiles:
      mountPath: /opt/app-root/src
      configMaps:
        - name: rbac-policies</pre><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
								For a Helm-installed RHDH instance:
							</li></ul></div></li><li class="listitem"><p class="simpara">
						Configure the required RBAC permission by defining an <code class="literal">rbac-policies.csv</code> file:
					</p><pre class="programlisting language-csv">p, role:default/_&lt;your_team&gt;_, lightspeed.chat.read, read, allow
p, role:default/_&lt;your_team&gt;_, lightspeed.chat.create, create, allow
p, role:default/_&lt;your_team&gt;_, lightspeed.chat.delete, delete, allow
g, user:default/_&lt;your_user&gt;_, role:default/_&lt;your_team&gt;_</pre></li><li class="listitem"><p class="simpara">
						Optional: Declare policy administrators by editing your custom RHDH ConfigMap (<code class="literal">app-config.yaml</code>) and adding the following code to enable selected authenticated users to configure RBAC policies through the REST API or Web UI:
					</p><pre class="programlisting language-yaml">  permission:
    enabled: true
    rbac:
      policies-csv-file: /opt/app-root/src/rbac-policies.csv
      policyFileReload: true
    admin:
      users:
        - name: user:default/&lt;your_policy_administrator_name&gt;</pre></li></ol></div><div class="orderedlist"><p class="title"><strong>Verification</strong></p><ol class="orderedlist" type="1"><li class="listitem">
						Log in to your RHDH instance.
					</li><li class="listitem">
						Verify that you can see and access the <span class="strong strong"><strong>Lightspeed</strong></span> FAB in the home page.
					</li><li class="listitem">
						Select the <span class="strong strong"><strong>Lightspeed</strong></span> FAB and verify the chat screen loads.
					</li></ol></div></section><section class="section" id="customizing-developer-lightspeed"><div class="titlepage"><div><div><h3 class="title">1.5. Customizing Developer Lightspeed for RHDH</h3></div></div></div><p>
				You can customize Developer Lightspeed for RHDH functionalities such as gathering feedback, storing chat history in PostgreSQL, and <a class="link" href="https://docs.redhat.com/en/documentation/red_hat_developer_hub/1.9/html-single/interacting_with_model_context_protocol_tools_for_red_hat_developer_hub/index#proc-configure-mcp-tools-for-developer-lightspeed_assembly-model-context-protocol-tools">configuring Model Context Protocol (MCP) tools</a>.
			</p><section class="section" id="proc-gathering-feedback_customizing-developer-lightspeed"><div class="titlepage"><div><div><h4 class="title">1.5.1. Gathering feedback in Developer Lightspeed for RHDH</h4></div></div></div><p>
					Feedback collection is an optional feature configured on the LCS. This feature gathers user feedback by providing thumbs-up/down ratings and text comments directly from the chat window.
				</p><p>
					LCS collects the feedback, the user’s query, and the response of the model, storing the data as a JSON file on the local file system of the Pod. A platform administrator must later collect and analyze this data to assess model performance and improve the user experience.
				</p><p>
					The collected data resides in the cluster where RHDH and LCS are deployed, making it accessible only to platform administrators for that cluster. For data removal, users must request this action from their platform administrator, as Red Hat neither collects nor accesses this data.
				</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							To enable feedback collection, in the LCS configuration file (<code class="literal">lightspeed-stack.yaml</code>), add the following settings:
						</p><pre class="programlisting language-yaml">  user_data_collection:
    feedback_enabled: true
    feedback_storage: "/tmp/data/feedback"
    transcripts_enabled: true
    transcripts_storage: "/tmp/data/transcripts"</pre></li><li class="listitem"><p class="simpara">
							To disable feedback collection, in the LCS configuration file (<code class="literal">lightspeed-stack.yaml</code>), add the following settings:
						</p><pre class="programlisting language-yaml">  user_data_collection:
    feedback_enabled: false
    feedback_storage: "/tmp/data/feedback"
    transcripts_enabled: true
    transcripts_storage: "/tmp/data/transcripts"</pre></li></ul></div></section><section class="section" id="proc-updating-the-system-prompt_customizing-developer-lightspeed"><div class="titlepage"><div><div><h4 class="title">1.5.2. Updating the system prompt in Developer Lightspeed for RHDH</h4></div></div></div><p>
					You can override the default system prompt that Developer Lightspeed for RHDH uses to better frame queries to your LLM. Customizing the system prompt allows you to refine the context, personality, and instructions that the LLM receives, improving the relevance and accuracy of the responses it creates for your specific environment.
				</p><div class="itemizedlist"><p class="title"><strong>Procedure</strong></p><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
							To set a custom system prompt, in your Developer Lightspeed for RHDH app config file, add or modify the <code class="literal">lightspeed.systemPrompt</code> key and set its value to your preferred prompt string as shown in the following example:
						</p><pre class="programlisting language-yaml">lightspeed:
  # ... other lightspeed configurations
  systemPrompt: "You are a helpful assistant focused on Red Hat Developer Hub development."</pre></li></ul></div><p>
					Set <code class="literal">systemPrompt</code> to prefix all queries sent by Developer Lightspeed for RHDH to the LLM with this instruction, guiding the model to generate more tailored responses.
				</p></section><section class="section" id="proc-customizing-the-chat-history-storage_customizing-developer-lightspeed"><div class="titlepage"><div><div><h4 class="title">1.5.3. Customizing the chat history storage in Developer Lightspeed for RHDH</h4></div></div></div><p>
					By default, the Developer Lightspeed for RHDH service stores chat history in a non-persistent local SQL database within the LCS container. This means that chat history is lost if you create and use a new LCS sidecar. You can manually configure Developer Lightspeed for RHDH to store the chat history persistently as a long-term backup with PostgreSQL by updating your LCS service configuration.
				</p><div class="admonition warning"><div class="admonition_header">Warning</div><div><p>
						Configuring Developer Lightspeed for RHDH to use PostgreSQL records prompts and responses, which platform administrators can review. You must assess any data privacy and security implications if user chat history contains private, sensitive, or confidential information. For users that wish to have their chat data removed, they must request their respective platform administrator to perform this action. Red Hat does not collect or access this chat history data.
					</p></div></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Configure the chat history storage type in the LCS configuration file (<code class="literal">lightspeed-stack.yaml</code>) using any of the relevant options:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem"><p class="simpara">
									To enable persistent storage with PostgreSQL, add the following configuration:
								</p><pre class="programlisting language-yaml"> conversation_cache:
    type: postgres
    postgres:
      host: _&lt;your_database_host&gt;_
      port: _&lt;your_database_port&gt;_
      db: _&lt;your_database_name&gt;_
      user: _&lt;your_user_name&gt;_
      password: _&lt;postgres_password&gt;_</pre><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
											To retain the default, non-persistent SQLite storage, make sure the configuration is set as shown in the following example:
										</p><pre class="programlisting language-yaml">conversation_cache:
  type: "sqlite"
  sqlite:
    db_path: "/tmp/data/conversations/lcs_cache.db"</pre></li></ul></div></li></ul></div></li><li class="listitem">
							Restart your LCS service to apply the new configuration.
						</li></ol></div></section></section><section class="section" id="get-ai-assisted-help"><div class="titlepage"><div><div><h3 class="title">1.6. Get AI-assisted help for your development tasks</h3></div></div></div><p>
				To assist with development tasks, platform questions, and debugging, use Red Hat Developer Lightspeed for Red Hat Developer Hub, a generative AI virtual assistant integrated directly into Red Hat Developer Hub (RHDH). You can use the conversational interface to ask platform-specific questions, analyze logs, generate code, and create test plans, which reduces the time spent searching through official documentation or disparate tools.
			</p><section class="section" id="proc-configure-safety-guards-rhdh_customizing-developer-lightspeed"><div class="titlepage"><div><div><h4 class="title">1.6.1. Configure safety guards in Red Hat Developer Hub</h4></div></div></div><p>
					To protect users from insecure or harmful AI model outputs, Red Hat Developer Hub (RHDH) uses Llama Guard as a default safety shield. You must configure these guards to align with your organization’s security policies.
				</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">Default safety guard configuration</code></span></dt><dd>
								The system uses Llama Guard as the default safety shield. Override these settings in the <code class="literal">run.yaml</code> file.
							</dd></dl></div><div class="admonition note"><div class="admonition_header">Note</div><div><p>
						The <code class="literal">external_providers_dir</code> parameter defaults to null and is no longer required in your configuration.
					</p></div></div><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">Overriding safety guards</code></span></dt><dd>
								To implement custom security layers or different safety shields, you must define a new safety provider within a custom <code class="literal">run.yaml</code> file.
							</dd><dt><span class="term"><code class="literal">Disabling safety guards</code></span></dt><dd>
								To run RHDH without safety guards, you must use the <code class="literal">run-no-guard.yaml</code> configuration file.
							</dd></dl></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						Running without safety guards increases the risk of unvalidated model output. Only use this configuration in secure development environments.
					</p></div></div><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">Applying the no-guard configuration</code></span></dt><dd>
								To run the system without a safety guard, perform these steps:
							</dd></dl></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem"><p class="simpara">
							Add the following YAML file as a config map to your namespace:
						</p><pre class="programlisting language-yaml">version: 2
image_name: redhat-ai-dev-llama-stack-no-guard
apis:
  - agents
  - inference
  - safety
  - tool_runtime
  - vector_io
  - files
container_image:
external_providers_dir:
providers:
  agents:
    - config:
        persistence:
          agent_state:
            namespace: agents
            backend: kv_default
          responses:
            table_name: responses
            backend: sql_default
      provider_id: meta-reference
      provider_type: inline::meta-reference
  inference:
    - provider_id: ${env.ENABLE_VLLM:+vllm}
      provider_type: remote::vllm
      config:
        url: ${env.VLLM_URL:=}
        api_token: ${env.VLLM_API_KEY:=}
        max_tokens: ${env.VLLM_MAX_TOKENS:=4096}
        tls_verify: ${env.VLLM_TLS_VERIFY:=true}
    - provider_id: ${env.ENABLE_OLLAMA:+ollama}
      provider_type: remote::ollama
      config:
        url: ${env.OLLAMA_URL:=http://localhost:11434}
    - provider_id: ${env.ENABLE_OPENAI:+openai}
      provider_type: remote::openai
      config:
        api_key: ${env.OPENAI_API_KEY:=}
    - provider_id: ${env.ENABLE_VERTEX_AI:+vertexai}
      provider_type: remote::vertexai
      config:
        project: ${env.VERTEX_AI_PROJECT:=}
        location: ${env.VERTEX_AI_LOCATION:=us-central1}
    - provider_id: sentence-transformers
      provider_type: inline::sentence-transformers
      config: {}
  tool_runtime:
    - provider_id: model-context-protocol
      provider_type: remote::model-context-protocol
      config: {}
    - provider_id: rag-runtime
      provider_type: inline::rag-runtime
      config: {}
  vector_io:
    - provider_id: faiss
      provider_type: inline::faiss
      config:
        persistence:
          namespace: vector_io::faiss
          backend: faiss_kv
  files:
    - provider_id: localfs
      provider_type: inline::localfs
      config:
        storage_dir: /tmp/llama-stack-files
        metadata_store:
          table_name: files_metadata
          backend: sql_files
storage:
  backends:
    kv_default:
      type: kv_sqlite
      db_path: /tmp/kvstore.db
    sql_default:
      type: sql_sqlite
      db_path: /tmp/sql_store.db
    sql_files:
      type: sql_sqlite
      db_path: /rag-content/vector_db/rhdh_product_docs/1.9/files_metadata.db
    faiss_kv:
      type: kv_sqlite
      db_path: /rag-content/vector_db/rhdh_product_docs/1.9/faiss_store.db
  stores:
    metadata:
      namespace: registry
      backend: faiss_kv
    inference:
      table_name: inference_store
      backend: sql_default
      max_write_queue_size: 10000
      num_writers: 4
    conversations:
      table_name: openai_conversations
      backend: sql_default
registered_resources:
  models:
    - model_id: sentence-transformers/all-mpnet-base-v2
      metadata:
        embedding_dimension: 768
      model_type: embedding
      provider_id: sentence-transformers
      provider_model_id: /rag-content/embeddings_model
  tool_groups:
    - provider_id: rag-runtime
      toolgroup_id: builtin::rag
  vector_dbs:
    - vector_db_id: rhdh-product-docs-1_8
      embedding_model: sentence-transformers/all-mpnet-base-v2
      embedding_dimension: 768
      provider_id: faiss
server:
  auth:
  host:
  port: 8321
  quota:
  tls_cafile:
  tls_certfile:
  tls_keyfile:</pre></li><li class="listitem"><p class="simpara">
							Mount the config map to your Llama Stack container at <code class="literal">/app-root/run.yaml</code> to make sure it overrides the default image file:
						</p><pre class="programlisting language-yaml">name: llama-stack
volumeMounts:
- mountPath: /app-root/run.yaml
  subPath: run.yaml
  name: llama-stack-config</pre></li><li class="listitem"><p class="simpara">
							Configure the required volume:
						</p><pre class="programlisting language-yaml">volumes:
- name: llama-stack-config
  configMap:
    name: llama-stack-config</pre><p class="simpara">
							where:
						</p><div class="variablelist"><dl class="variablelist"><dt><span class="term"><code class="literal">llama-stack-config</code></span></dt><dd>
										The config map where you added the new no-guard configuration file.
									</dd></dl></div></li><li class="listitem">
							Restart the deployment if it does not trigger an automatic rollout.
						</li></ol></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							Your platform engineer has installed and configured the Developer Lightspeed for RHDH plugin in your RHDH instance.
						</li></ul></div></section><section class="section" id="ref-get-the-best-results-for-assistant-queries_customizing-developer-lightspeed"><div class="titlepage"><div><div><h4 class="title">1.6.2. Get the best results for assistant queries</h4></div></div></div><p>
					To resolve technical blockers and accelerate development tasks, you must structure your queries to provide specific context to the AI assistant. Using precise prompts ensures that Developer Lightspeed for RHDH generates relevant code snippets, architectural advice, or platform-specific instructions.
				</p><p>
					Use the following strategies to improve the accuracy of the assistant’s output during your development workflow:
				</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Specify technologies</span></dt><dd>
								Instead of asking "How do I use templates?", ask "How do I create a Software Template that scaffolds a Node.js service with a CI/CD pipeline".
							</dd><dt><span class="term">Provide context</span></dt><dd>
								Include details about your environment, such as "I am deploying to OpenShift; how do I configure my catalog-info.yaml to show pod health?".
							</dd><dt><span class="term">Leverage conversation context</span></dt><dd>
								Ask follow-up questions to refine a previous answer. For example, if the assistant provides a code snippet, you can ask "Now rewrite that using TypeScript interfaces."
							</dd><dt><span class="term">Validate with citations</span></dt><dd>
								Examine the provided documentation links and citations in the response to verify that the generated advice aligns with your organization’s official standards.
							</dd><dt><span class="term">Improve assistant accuracy</span></dt><dd>
								Rate the utility of responses by selecting the <span class="strong strong"><strong>Thumbs up</strong></span> or <span class="strong strong"><strong>Thumbs down</strong></span> icons. This feedback helps tune the model for your organization’s specific requirements.
							</dd></dl></div><div class="admonition important"><div class="admonition_header">Important</div><div><p>
						To maintain security standards, do not include sensitive personal information, plain-text credentials, or confidential business data in your queries.
					</p></div></div></section><section class="section" id="con-monitor-ai-responses-and-context-management_customizing-developer-lightspeed"><div class="titlepage"><div><div><h4 class="title">1.6.3. Monitor AI responses and context management</h4></div></div></div><p>
					Developer Lightspeed for RHDH provides features to track the AI reasoning process and maintain the context of your development tasks.
				</p><div class="variablelist"><dl class="variablelist"><dt><span class="term">Thinking cards</span></dt><dd>
								An expandable thinking card appears while the AI processes a query. A pulse animation indicates the reasoning phase. You can expand the card to view detailed reasoning or collapse it to minimize screen clutter.
							</dd><dt><span class="term">Tool call transparency</span></dt><dd>
								An expandable card displays details for Model Context Protocol (MCP) tool calls, which allows you to monitor background processes.
							</dd><dt><span class="term">Context-aware citations</span></dt><dd>
								Retrieval-Augmented Generation (RAG) citations appear only when the AI uses internal documentation. This makes sure that general knowledge responses remain concise.
							</dd><dt><span class="term">Context preservation during model changes</span></dt><dd>
								When you select a different AI model, Developer Lightspeed for RHDH starts a new conversation. This makes sure that your previous chats remain available in your history.
							</dd><dt><span class="term">Structural readability</span></dt><dd>
								The interface formats headings and bullet points automatically to make sure responses are scannable.
							</dd></dl></div></section><section class="section" id="proc-managing-chats_customizing-developer-lightspeed"><div class="titlepage"><div><div><h4 class="title">1.6.4. Managing chats</h4></div></div></div><p>
					Manage your chat history in RHDH to organize your workspace, resume previous tasks, or find past solutions.
				</p><div class="informalfigure"><div class="mediaobject"/></div><div class="itemizedlist"><p class="title"><strong>Prerequisites</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							You have configured the Developer Lightspeed for RHDH plugin in Red Hat Developer Hub.
						</li><li class="listitem">
							You must be logged in to the portal.
						</li></ul></div><div class="orderedlist"><p class="title"><strong>Procedure</strong></p><ol class="orderedlist" type="1"><li class="listitem">
							Click the <span class="strong strong"><strong>Lightspeed</strong></span> floating action button (FAB) at the bottom right of the screen to open the chat overlay.
						</li><li class="listitem"><p class="simpara">
							Optional: Configure the interface display:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									Click the <span class="strong strong"><strong>Chatbot options icon</strong></span> (⋮) to view chat history or start a new chat.
								</li><li class="listitem"><p class="simpara">
									Click the <span class="strong strong"><strong>Display menu</strong></span> icon and select any of the following views:
								</p><div class="informalfigure"><div class="mediaobject"/></div><div class="itemizedlist"><ul class="itemizedlist" type="circle"><li class="listitem"><p class="simpara">
											<span class="strong strong"><strong>Overlay</strong></span>: A floating window appears over the current page content.
										</p><div class="informalfigure"><div class="mediaobject"/></div></li><li class="listitem"><p class="simpara">
											<span class="strong strong"><strong>Dock to window</strong></span>: A panel attaches to the right side of the screen. Activating this mode automatically closes the <span class="strong strong"><strong>Quickstart</strong></span> panel if it is already open.
										</p><div class="informalfigure"><div class="mediaobject"/></div></li><li class="listitem"><p class="simpara">
											<span class="strong strong"><strong>Fullscreen</strong></span>: A dedicated page opens for intensive chat sessions. You can bookmark this URL for direct access.
										</p><div class="informalfigure"><div class="mediaobject"/></div></li><li class="listitem">
											Optional: Toggle <span class="strong strong"><strong>Enable pinned chats</strong></span>/<span class="strong strong"><strong>Disable pinned chats</strong></span> to enable or hide the pinned chats. This is enabled by default.
										</li></ul></div></li></ul></div></li><li class="listitem"><p class="simpara">
							Start a chat or load a previous session:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									<span class="strong strong"><strong>Enter a prompt</strong></span>: Type a query in the <span class="strong strong"><strong>Enter a prompt for Lightspeed</strong></span> chat field and press <span class="strong strong"><strong>Enter</strong></span>.
								</li><li class="listitem">
									<span class="strong strong"><strong>Use a sample</strong></span>: Click a prompt tile, such as <span class="strong strong"><strong>Deploy with Tekton</strong></span>.
								</li><li class="listitem"><p class="simpara">
									<span class="strong strong"><strong>Attach a file</strong></span>: Click <span class="strong strong"><strong>Attach</strong></span> to upload a <code class="literal">.yaml</code>, <code class="literal">.json</code>, or <code class="literal">.txt</code> file.
								</p><div class="orderedlist"><ol class="orderedlist" type="i"><li class="listitem">
											Click the file name to open the preview model.
										</li><li class="listitem"><p class="simpara">
											View or edit the content of the file:
										</p><div class="informalfigure"><div class="mediaobject"/></div></li></ol></div></li><li class="listitem">
									<span class="strong strong"><strong>Use voice</strong></span>: Click the <span class="strong strong"><strong>Use microphone</strong></span> icon.
								</li><li class="listitem">
									<span class="strong strong"><strong>Resume a chat</strong></span>: Select a title from the <span class="strong strong"><strong>Recent</strong></span> list.
								</li></ul></div></li><li class="listitem"><p class="simpara">
							Organize your chat history:
						</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
									<span class="strong strong"><strong>Start a new topic</strong></span>: Click <span class="strong strong"><strong>New chat</strong></span> to reset the assistant’s context.
								</li><li class="listitem">
									<span class="strong strong"><strong>Search history</strong></span>: Enter a keyword in the <span class="strong strong"><strong>Search</strong></span> field.
								</li><li class="listitem"><p class="simpara">
									<span class="strong strong"><strong>Rename a session</strong></span>: Click <span class="strong strong"><strong>Options</strong></span> next to a chat title, select <span class="strong strong"><strong>Rename</strong></span>, and enter a new name.
								</p><div class="informalfigure"><div class="mediaobject"/></div></li><li class="listitem">
									<span class="strong strong"><strong>Pin a chat</strong></span>:: Click <span class="strong strong"><strong>Options</strong></span> next to a chat title and select <span class="strong strong"><strong>Pin</strong></span>. The chat moves to the <span class="strong strong"><strong>Pinned</strong></span> group.
								</li><li class="listitem"><p class="simpara">
									<span class="strong strong"><strong>Sort chats</strong></span>:: Click <span class="strong strong"><strong>Sort</strong></span> control and choose a sorting criteria, such as <span class="strong strong"><strong>Date (Newest first)</strong></span>.
								</p><div class="informalfigure"><div class="mediaobject"/></div></li><li class="listitem"><p class="simpara">
									<span class="strong strong"><strong>Delete a chat</strong></span>: Click <span class="strong strong"><strong>Options</strong></span> next to a chat title and select <span class="strong strong"><strong>Delete</strong></span>.
								</p><div class="informalfigure"><div class="mediaobject"/></div></li><li class="listitem">
									<span class="strong strong"><strong>Hide the chat history section and reduce visual noise</strong></span>: Select the <span class="strong strong"><strong>Close</strong></span> icon (x) next to <span class="strong strong"><strong>New chat</strong></span>.
								</li><li class="listitem">
									<span class="strong strong"><strong>Restore access to your pinned chat</strong></span>: Select the <span class="strong strong"><strong>Chat history menu</strong></span> icon.
								</li></ul></div></li><li class="listitem">
							Optional: To hide the interface, if you are in the <span class="strong strong"><strong>Overlay</strong></span> or <span class="strong strong"><strong>Dock to window</strong></span> mode, click the <span class="strong strong"><strong>Close Lightspeed</strong></span> icon (X) to hide the window. If you are in <span class="strong strong"><strong>Fullscreen</strong></span> mode, revert to the other modes and click the <span class="strong strong"><strong>Close Lightspeed</strong></span> icon (X). The system preserves your active query and history.
						</li><li class="listitem">
							Optional: In <span class="strong strong"><strong>Fullscreen</strong></span> mode, bookmark the URL in your browser to save a direct link to the chat interface.
						</li></ol></div><div class="itemizedlist"><p class="title"><strong>Verification</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							The main window displays the active chat or selected history.
						</li><li class="listitem">
							The chat history list reflects renamed, pinned, or deleted entries.
						</li></ul></div></section></section><section class="section" id="appendix-llm-requirements"><div class="titlepage"><div><div><h3 class="title">1.7. Appendix: LLM requirements</h3></div></div></div><section class="section" id="con-llm-requirements_appendix-llm-requirements"><div class="titlepage"><div><div><h4 class="title">1.7.1. Large language model (LLM) requirements</h4></div></div></div><p>
					Developer Lightspeed for RHDH follows a <span class="emphasis"><em>Bring Your Own Model</em></span> approach. This model means that to function, Developer Lightspeed for RHDH requires access to a large language model (LLM) which you must provide. An LLM is a type of generative AI that interprets natural language and generates human-like text or audio responses. When an LLM is used as a virtual assistant, the LLM can interpret questions and provide answers in a conversational manner.
				</p><p>
					LLMs are usually provided by a service or server. Because Developer Lightspeed for RHDH does not provide an LLM for you, you must configure your preferred LLM provider during installation. You can configure the underlying Llama Stack server to integrate with a number of LLM <code class="literal">providers</code> that offer compatibility with the OpenAI API including the following inference providers:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							OpenAI (cloud-based inference service)
						</li><li class="listitem">
							Red Hat OpenShift AI (enterprise model builder and inference server)
						</li><li class="listitem">
							Red Hat Enterprise Linux AI (enterprise inference server)
						</li><li class="listitem">
							Ollama (popular desktop inference server)
						</li><li class="listitem">
							vLLM (popular enterprise inference server)
						</li><li class="listitem">
							Gemini (available through Vertex AI)
						</li></ul></div></section><section class="section" id="con-openai_appendix-llm-requirements"><div class="titlepage"><div><div><h4 class="title">1.7.2. OpenAI</h4></div></div></div><p>
					OpenAI offers a range of generative AI models, such as GPT 5, which can be used to provide inference services for applications like Developer Lightspeed for RHDH.
				</p><p>
					To use OpenAI with Developer Lightspeed for RHDH, you need access to the OpenAI <a class="link" href="https://openai.com/api/">API platform</a>. For more information, see the <a class="link" href="https://platform.openai.com/docs/overview">OpenAI developer platform documentation</a>.
				</p></section><section class="section" id="con-ollama_appendix-llm-requirements"><div class="titlepage"><div><div><h4 class="title">1.7.3. Ollama</h4></div></div></div><p>
					Ollama is a powerful and easy-to-use open-source project that simplifies the process of running large language models (LLMs) locally on your computer. It provides a simple command-line interface for downloading, managing, and running a wide variety of open-source models, such as Llama 3, Mistral, and many others, all without requiring a dedicated server or cloud service. By abstracting away the complex setup and dependencies, Ollama makes it accessible for developers, researchers, and enthusiasts to experiment with, build on, and integrate state-of-the-art LLMs into their applications directly from their personal machines.
				</p><p>
					The open source Ollama server in container form provides a convenient local testbed for LLM models that is very accessible and easily controlled.
				</p><div class="itemizedlist"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							<a class="link" href="https://ollama.com">Ollama</a>
						</li><li class="listitem">
							<a class="link" href="https://hub.docker.com/r/ollama/ollama">Ollama server container</a>
						</li></ul></div></section><section class="section" id="con-vllm_appendix-llm-requirements"><div class="titlepage"><div><div><h4 class="title">1.7.4. vLLM</h4></div></div></div><p>
					<a class="link" href="https://docs.vllm.ai/en/stable/">vLLM</a> is an open-source, high-throughput serving engine for large language models (LLMs) that significantly improves upon traditional serving systems. It achieves this by introducing several key optimizations to reduce memory usage and eliminate redundant computations. vLLM prominently increases the number of concurrent requests an LLM can handle, making it a powerful tool for deploying and scaling LLM-based applications.
				</p></section></section><section class="section" id="appendix-about-user-data-security"><div class="titlepage"><div><div><h3 class="title">1.8. Appendix About user data security</h3></div></div></div><section class="section" id="con-about-data-use_appendix-about-user-data-security"><div class="titlepage"><div><div><h4 class="title">1.8.1. About data use</h4></div></div></div><p>
					Developer Lightspeed for RHDH is a virtual assistant you interact with using natural language. Using the Developer Lightspeed for RHDH interface, you send chat messages that Developer Lightspeed for RHDH transforms and sends to the large language model (LLM) provider you have configured for your environment. These messages could potentially contain information provided by your users about themselves, your cluster, cluster resources, or other aspects of your business or working environment.
				</p><p>
					Developer Lightspeed for RHDH has limited capabilities to filter or redact the information you provide to the LLM. Do not enter information into Developer Lightspeed for RHDH that you do not want to send to the LLM provider. To remind end users not to share private or confidential information, Developer Lightspeed for RHDH begins each new chat with an 'Important' message asking them not to “include personal or sensitive information” in their chat messages.
				</p></section><section class="section" id="con-about-feedback-collection_appendix-about-user-data-security"><div class="titlepage"><div><div><h4 class="title">1.8.2. About feedback collection</h4></div></div></div><p>
					Developer Lightspeed for RHDH collects feedback from users who engage with the feedback feature in the virtual assistant interface. If a user submits feedback, the feedback score (thumbs up or down), text feedback (if entered), the user query, and the LLM provider response are stored locally in the file system of the Pod. Red Hat does not have access to the collected feedback data.
				</p></section><section class="section" id="con-about-bring-your-own-model_appendix-about-user-data-security"><div class="titlepage"><div><div><h4 class="title">1.8.3. About Bring Your Own Model</h4></div></div></div><p>
					Developer Lightspeed for RHDH does not provide its own inference services, but uses a <span class="emphasis"><em>Bring Your Own Model</em></span> approach. This means that you can configure the Lightspeed Core Service to talk to the inference server or service of your choice. This also means that you are responsible for ensuring that the configured service meets your particular company policies and legal requirements, including any applicable terms with the third-party model provider. The only technical requirements for inference services are:
				</p><div class="itemizedlist"><ul class="itemizedlist" type="disc"><li class="listitem">
							The service must conform to the OpenAI API specification.
						</li><li class="listitem">
							The service must be configured correctly following the installation and configuration instructions. There are many commercial and open source inference services that support the OpenAI API specification for chat completions. The cost, performance, and security of these services can differ and it is up to you to choose, through evaluation and testing, the inference service that best meets your company’s needs.
						</li></ul></div><div class="itemizedlist"><p class="title"><strong>Additional resources</strong></p><ul class="itemizedlist" type="disc"><li class="listitem">
							<a class="link" href="https://github.com/openai/openai-openapi/tree/manual_spec">OpenAI API specification</a>
						</li></ul></div></section><section class="section" id="con-your-responsibility_appendix-about-user-data-security"><div class="titlepage"><div><div><h4 class="title">1.8.4. Your responsibility</h4></div></div></div><p>
					All of the information your users share in their questions and responses with Developer Lightspeed for RHDH are shared with the LLM inference service you configured. You are responsible for ensuring compliance with your company’s policies regarding the sharing of data with your chosen inference service.
				</p></section></section></section><div><div xml:lang="en-US" class="legalnotice" id="idm46463587173968"><h1 class="legalnotice">Legal Notice</h1><div class="para">
		Copyright <span class="trademark"/>© 2026 Red Hat, Inc.
	</div><div class="para">
		The text of and illustrations in this document are licensed by Red Hat under a Creative Commons Attribution–Share Alike 3.0 Unported license ("CC-BY-SA"). An explanation of CC-BY-SA is available at <a class="uri" href="http://creativecommons.org/licenses/by-sa/3.0/">http://creativecommons.org/licenses/by-sa/3.0/</a>. In accordance with CC-BY-SA, if you distribute this document or an adaptation of it, you must provide the URL for the original version.
	</div><div class="para">
		Red Hat, as the licensor of this document, waives the right to enforce, and agrees not to assert, Section 4d of CC-BY-SA to the fullest extent permitted by applicable law.
	</div><div class="para">
		Red Hat, Red Hat Enterprise Linux, the Shadowman logo, the Red Hat logo, JBoss, OpenShift, Fedora, the Infinity logo, and RHCE are trademarks of Red Hat, Inc., registered in the United States and other countries.
	</div><div class="para">
		<span class="trademark">Linux</span>® is the registered trademark of Linus Torvalds in the United States and other countries.
	</div><div class="para">
		<span class="trademark">Java</span>® is a registered trademark of Oracle and/or its affiliates.
	</div><div class="para">
		<span class="trademark">XFS</span>® is a trademark of Silicon Graphics International Corp. or its subsidiaries in the United States and/or other countries.
	</div><div class="para">
		<span class="trademark">MySQL</span>® is a registered trademark of MySQL AB in the United States, the European Union and other countries.
	</div><div class="para">
		<span class="trademark">Node.js</span>® is an official trademark of Joyent. Red Hat is not formally related to or endorsed by the official Joyent Node.js open source or commercial project.
	</div><div class="para">
		The <span class="trademark">OpenStack</span>® Word Mark and OpenStack logo are either registered trademarks/service marks or trademarks/service marks of the OpenStack Foundation, in the United States and other countries and are used with the OpenStack Foundation's permission. We are not affiliated with, endorsed or sponsored by the OpenStack Foundation, or the OpenStack community.
	</div><div class="para">
		All other trademarks are the property of their respective owners.
	</div></div></div></section></div></div><script type="text/javascript">
                        jQuery(document).ready(function() {
                            initSwitchery();
                            jQuery('pre[class*="language-"]').each(function(i, block){hljs.highlightBlock(block);});
                        });
                    </script></body></html>